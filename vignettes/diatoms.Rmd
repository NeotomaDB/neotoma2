---
title: "Working with diatom data in the `neotoma2` R package"
output:
  rmarkdown::html_vignette: default
  html_vignette:
    toc: yes
    toc_depth: 4
vignette: |
  %\VignetteIndexEntry{Working with diatom data in the neotoma2 R package} %\VignetteEngine{knitr::rmarkdown} %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup}
library(neotoma2)
library(neotoma)
library(dplyr)
library(purrr)
library(sf)
```

## Introduction

This document provides general guidance and specific code examples for those wanting to use `neotoma2` to retrieve and work with diatom data from the Neotoma Paleoecology Database.  This vignette, as part of the `neotoma2` package, also provides the package developers (Socorro Dominguez and Simon Goring) a set of  structured descriptions for the kinds of work that diatom researchers may wish to perform with Neotoma data, and some of the specific tasks they may wish to accomplish.  Researchers who would like to add examples, or other workflows can reach out to the developers through [GitHub Issues](https://github.com/NeotomaDB/neotoma2/issues), or the [Neotoma Slack Workspace](https://join.slack.com/t/neotomadb/shared_invite/zt-cvsv53ep-wjGeCTkq7IhP6eUNA9NxYQ).

Some code in this document was borrowed from the `neotoma2` markdown document prepared by Simon Goring and Socorro Dominguez and the original Neotoma R package ([Goring et al. 2015](http://doi.org/10.5334/oq.ab)).

One of the main goals of `neotoma2` is to pull records out of the Neotoma database and into a user's R workflow.  This will help diatomists and environmental scientists produce clear working documents, that use data from Neotoma, and allow them to combine it with their own data, or data from other sources.

> If you’re thinking without writing, you only think you’re thinking. — *Leslie Lamport*

`neotoma2` was being developed while this vignette documentation was being prepared, so not all the original package functions were available.  Currently, some functions from both `neotoma` and `neotoma2` are used.  Over time, original package functions should be replaced with corresponding `neotoma2` functions. In the code chunks below, `neotoma::` is used to refer to functions in the original neotoma R package, for example, **`neotoma::`**`get_site(whatever)`.

This document is organized to address two main goals of users, to browse the database to discover datasets that meet specified criteria, and to create output files that can be used for further analysis.  Other goals are to create plots and maps and to analyze data using R code.

### Why `neotoma2` and not just an update?

The Neotoma servers and all the back-end services recently [Simon - add month / year] migrated from a SQL Server Database on a lonely Windows N95 computer to a more robust server and set of services.  Because of this migration, a large number of the tools we use to access data are no longer accessible.  For this reason, we [Simon - Neotoma IT Team?] made the choice to create a new package.  This is because code that is run using `neotoma` will not be directly comparable to code using `neotoma2`, since data objects and expected behaviours will be different.

### Data Organization in Neotoma


Test


It's worth knowing a bit about how the Neotoma database is organized, and what we mean when we talk about things like "sites", "datasets" and "samples".  The database itself is a Postgres database.  People who are comfortable with SQL can download a snapshot of the database and run much of the analysis on their own [directly].

#### What is the R package doing?

When you work with the `neotoma2` package you are working with data from the database, but it is mediated through R functions (like `get_sites()` to get site information) that themselves call public URLs, that are basically abstractions of database calls.  So, for example:

```r
get_sites(siteid=12)
```

actually calls out to the internet for the result at:

```
https://api.neotomadb.org/v2.0/data/sites/12
```

Which itself calls a SQL query:

```sql
SELECT * FROM ndb.sites
WHERE siteid = 12
```

So, for most users, it's a lot easier to just use the R functions, since they create objects in R, that work with other commands, and work with any of the statistical analysis you might want to do.

#### What does the data look like?

The Neotoma data model is available online at the [Database Schema](https://open.neotomadb.org/dbschema) page.  [At the time of writing there are - DELETE] [ADD - As of September 2021,there were] 150 different tables that store data for the database.  Some of these have particular kinds of data (for example, `agetypes`), some of these link tables together. The `neotoma2` package supports access to some tables directly, but not all.  For specialized cases a user may be required to directly access an entire table (using the `get_table()` function).

#### Sites, Datasets, etcetera

Neotoma data is structured spatially.  Each sample location is assigned a **site**.  A site is a spatial location, defined by either a point or a polygon.  It may be a lake, an archaeological site, a swamp, or some other location.

Within a **site** there may be one or more **collection units**.  A collection unit is the specific location where samples were collected.  So, a researcher may have taken multiple cores within a lake basin, or an archaeologist may have several dig sites within a larger area.  The collection unit represents the material that was removed and analyzed.  The material is subdivided into **analysis units** (e.g., sediment intervals within a core), and groups of analysis units, sampled for a particular dataset type (e.g., diatoms, pollen, water chemistry) are then grouped into a **dataset**.  [Simon - describe "Samples" also?]

## Browsing - Data discovery

This section describes ways of searching the Neotoma database for available diatom datasets using a variety of criteria, either alone or in combination.  Criteria include those available in Neotoma Explorer, plus several more. Examples also include options for viewing and saving output results. The primary purpose of each code chunk in this section is to find the Dataset IDs for datasets that meet the criteria specified in the code.  The sets of IDs that are returned can then be used as input to other code chunks that return more detailed information on the datasets and create output files for data analysis (e.g., diatom counts).

### Finding Neotoma Sites

[Include brief explanation of differences between Neotoma R and Neotoma R2 ??.  Use R2!! Neotoma R@ Get_sites is working (totally?  altitude issues??) and provides more information than get_site.  Therefore, there is no reason to get use original R.]

We can search for information on a single or multiple sites.  Sometimes it is useful to find locations of all sites within a region, whether or not they are diatom sites.  This can give us an indication of the level of paleoecological 'effort' in a region.[Delete following sentence - A **site** may not be a diatom site, but **sites** do represent general "effort" in a region.]  We can often use a site search to do some preliminary work, since the `site` object that `neotoma2` returns contains less information than the larger `dataset` or `download` objects, that contain full metadata.  We might want to generate a map of all sites, and superimpose specific sites we are interested in, for example.



Sites can be searched using the following supported parameters:

| parameter | allowed values |
| ------ | ------- |
| `siteid` | integers (values > 0) |
| `sitename` | valid character string; `%` as wildcard |
| `altmax` | integers (values >= than `altmin`) |
| `altmin` | integers |
| `loc` | spatial coordinates (WKT or geoJSON) |
| `limit` | integer > 0; default 25 |
| `offset` | integer > 0; default 0 |

[Delete following sentence - duplicates sentence above]:Currently, the site search supports searches by elements such as location, altitude, name and other parameters.  We can also use the `sf` package to create polygons for spatial searches (the package also allows you to pass in geoJSON or WKT spatial objects).  Here we create a matrix to represent the bounding box of the northeastern United States and then create a spatial polygon to use it with the `get_sites()` function.

```{R siteSpatialSearch, eval = FALSE}

northeastUS <- rbind(c(-80,40), c(-80,48), 
                     c(-65,48), c(-65,40), c(-80,40))

neus <- sf::st_polygon(list(northeastUS))

neUSsites <- get_sites(loc = neus)
``` 

### Site Name

If we know the names of one or more of the existing sites that we are looking for, we can get site data using the `sitename` parameter.

Get data on a single site using sitename
```{r sitesbyName example}
# diat <- get_sites(sitename = "Name of site")  # Basic format
diat <- get_sites(sitename = 'Schrader Pond')  # Example
diat <- get_sites(sitename = '%Schra%')      # Example using wildcards (%)
```
Get data on multiple sites using sitenames.


```{r multsitesbySitename example}
# Join a list of site names together using the combine command, c()
sitenameList <- c("Bald Hill", "Blake (sutton)", 
                  "High (sudbry)", "Holland", 
                  "Little Hosmer", "Long (grnsbo)", 
                  "Long (shefld)", "Round (shefld)")
aa <- sitenameList %>% 
  map(function(x) get_sites(sitename=x))

```

Get data on multiple sites using sitenames - National Lakes Assessment Example

```{r NLA}
library(neotoma)
library(neotoma2)
# Join a list of site names together using the combine command, c()
nlaxl <- c("Gardner Pond","George Wyth Lake","Goose Pond","Gorton Pond","Grassy Pond","Green Belt Lake","Grimes","Grist Millpond","Grittman Lake","Groton Reservoir","Half Moon Lake","Halfway Pond","Hannaberry Lake","Harper Lake","Haskell Lake","Heggs","Henry's Lake","Hert Lake","Highland Lake","Hi-Land Lake","Hinkley's Pond","Horsfall Lake","Hosmer Lake")
nla_sites <- c() 
# Run a loop that gets sites for each name in the object containing lake names (nlaxl)
for(name in nlaxl){
sites <- get_site(sitename = name)
nla_sites <- c(nla_sites, sites)}  # The object nla-sites now contains the get_sites results for all lakes listed in nlaxl
```

### Site ID

Get data on a single site using siteid
```{r sitesbySiteID example}
# diat_3<-get_sites(siteid= x) - basic format
diat_4<-get_sites(siteid= 27408) # Example for single site (Schrader Pond)
#The get_site function will return basic metadata, e.g.,  sitename,location and collection unit 
```

Get data on multiple sites by using siteids.  
Here, we assume that an individual knows the siteids beforehand, or has obtained site IDs from the Neotoma Explorer or the Neotoma Landing Pages.

| `sitename` |  `siteid` |
| -- | -- |
| Jackson Pond | 25918 |
| Jellison Hill Pond | 25919 |
| Jimmie Pond | 25920 |
Get data on a multiple sites by using siteids
```{r multsitesbySiteIDs example}
siteids <- c(25918,25919,25920)
diat_6 <- get_sites(siteids)
```
Get data on multiple sites by reading a text file of siteids

The above code returns data for three sites.  We could use a larger set of site IDs either by loading the IDs from a file, or by entering them directly.  Here we assume that there exists a file called `NLAD.txt` with a list of site IDs in a plain text file for the National Lakes Assessment.  The contents of the file look like this (the ellipsis would be replaced by other numbers):

```
8556
10427
13527
23249
23250
...
24214
23264
23265
```

There may well be many more lines with numbers representing each site identifer in the set of records.  In this case we would load the data like so.:


```{r NLAmultiplesiteID, eval=FALSE}
nlad <- read.table('NLAD.txt', header=FALSE)
nlaSites <- get_sites(nlad)
#This code assumes that the text file is located in your working directory, which can be found with getwd()
```

### Dataset ID
Get data on a single dataset using datasetID 
```{r get datasetID}
# diat_ID <- get_dataset(datasetid) - basic format
diat_ID <- get_dataset(44764) # Example
diat_dow <- get_download(diat_ID)
browse (44764)
diat_comp<- compile_downloads(diat_dow)
#get_dataset could use site id or dataset id  to return information on site, metadata, publication, and date submitted 
```
Get data on multiple datasets using multiple dataset IDs 
```{r multdatsetid }
multid <- c(44764,44765,44766)
diat_multid <- get_dataset(multid) # Example
diat_down <- get_download(diat_multid)
diat_tab <-compile_downloads(diat_down)

write_xlsx(diat_tab,  ".xlsx")
#Multiple dataset ids combined to put in a object will run get_dataset so less code needs to be created 
```

Get Sample IDs for Dataset IDs
```{r GETSampleID for Dataset ID}
CODE <-c(44764,44765,44766)
C1<- get_dataset(CODE)
CD <- get_download(C1)
C2 <- sapply(CD, 
                 function(x) {
                   x$sample.meta$sample.id
                   })
C3 <-sapply(CD, 
                 function(x) {
                    x$dataset$dataset.meta
                   })
C4 <-sapply(CD, 
                 function(x) {
                  x$dataset$dataset.meta$dataset.id
                   })
```

(WORKING ON IT)
```{r}
s.data <- get_datasets(49223)
s.dl <- get_download(s.data)
S2 <- sapply(s.dl, 
                 function(x) {
                   x$sample.meta$sample.id
                   })
S3 <-sapply(s.dl, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })
```

```{R}
nla744<- read.table('VT744.txt', header=TRUE)

```

(IN PROGRESS)
```{r GetSampleIDs by Dataset IDs}
NL1 <- c(49022,49023,49024,49025,49026,49027,49028,49029,49030,49031,49032,49033,49034,49035,49036,49037,49038,49039,49040,49041)
NL2 <- get_datasets(NL1) %>%
       filter(datasettype == "Diatom")


NL3 <- get_download(NL2)
NL4 <- sapply(NL3, 
                 function(x) {
                   x$sample.meta$sample.id
                   })

```

### Dataset Type
Get dataset IDs by dataset type (Diatom, Diatom Surface Sample, Diatom Top-Bottom)

Example of combining data set types and using the variable to get dataset metadata from the combined object.  Example "loc = bounding box" (W,S,E,N) is northern Maine.
```{r getDiatoms, eval=FALSE} 
# Get datasets by individual diatom datatype 
neDiatoms_ss <- get_datasets(datasettype="diatom surface sample", loc= -70, 48, -68, 48)
neDiatoms_tb <- get_datasets(datasettype="diatom top-bottom", loc= -70, 48, -68, 48)
neDiatoms_dt <- get_datasets(datasettype="diatom", loc= -70, 48, -68, 48)
# Get datasets by multiple diatom datatypes 

neDiatoms_sstb <- c(neDiatoms_ss,neDiatoms_tb,neDiatoms_dt) 
#Returns the [Creates an?] object neDiatoms_sstb to contain the datasets of the different diatom data types in one place
# JERRIN / SIMON - code seems to work up to this point, but the following line does not work.

#Jerrin: The code for line 134 works but in Line 139 it is saying that it should be numerical and need to be siteID
neDiatoms_com <- get_datasets(neDiatoms_sstb)

# neDiatoms_com includes dataset information for all three diatom data types 
```

### Dataset type - Diatom, Diatom Surface Sample, Diatom Top Bottom

```{r getDiatomSurf, eval=FALSE}
neDiatoms <- get_datasets(datasettype="diatom surface samples", loc=BOUNDING BOX)

neDiatoms <- get_datasets(dois=c(...)) # DOI's
```

Example of combining datatypes and using the variable to get dataset 

```{r getDiatomComb, eval=FALSE} 
# Get datasets by individual diatom datatype 
neDiatoms_ss <- get_datasets(datasettype="diatom surface samples", loc=BOUNDING BOX)
neDiatoms_tb <- get_datasets(datasettype="diatom top-bottom", loc=BOUNDING BOX)
neDiatoms_dt <- get_datasets(datasettype="diatom", loc=BOUNDING BOX)
# Get datasets by multiple diatom datatypes 
neDiatoms_sstb <- combine(neDiatoms_ss,neDiatoms_tb,neDiatoms_dt) 
#The combine function would take all the datasettypes to form one object
neDiatoms_com <- get_datasets(neDiatoms_sstb)

```

### Geographic region
Using get_site to return a list of all sites located in a geopolitical unit as specified by gpid
```{r get site by gpid}
# diat_1<-get_site(gpid = x) - basic format
diat_1<-get_site(gpid = 6198) # Example using geopolitical ID for Alaska. The gpid was retreived from the GeoPoliticalUnits table 
diat_1
#
```

View the geopolitical table to search for locations and gpids
```{r getGeoPolUnits}
gpids <- neotoma::get_table(table.name='GeoPoliticalUnits')
gpids
#gpid is useful to find country and state boundaries 
```

Example - get sites from multiple geopolitical units (e.g., states)
```{r retrieveByGeopol}
library(dplyr)
library(purrr)

gpids <- c(8412, 7990, 7934, 7326, 7923, 8981, 6442, 7368)
ne_sites <- map(gpids, function(x)
  neotoma:::get_site(gpid = x)) %>%
  neotoma::bind()
ne_down <- neotoma::get_download(ne_sites)

#The gpids were found from Geopolitical units table 
#The code will run each gpid with the get_site that will be binded and than downloaded to display the data 
```

####  Geopolitical units (e.g., states)
```{R callDatasetsbygpid}
loc <- neotoma2::get_table(x='geopoliticalunits', limit = 10000)
diat_geo <- get_dataset(gpid = X)
```

Example - get_dataset for an individual state
```{R gpidExamplePenn}
loc <- get_table(table.name='GeoPoliticalUnits')
Geo_PA <- get_dataset(gpid = "Pennsylvania")
GEO_PA1 <- get_dataset(gpid = 8412 )
```

#### Latitude and Longitude boxes

```{R diatomsbyBBox}
# diat_LL <- get_datasets(datasettype="diatom", loc=BOUNDING BOX) - basic format
```

Example of get_datasets by location with bounding box of lat & longs (West/South/East/North)

```{R diatomsbyBBoxExecuted}
diat_NE <- get_dataset(datasettype="diatom",loc =c(-80,40,-65,48)) 
```

### Elevation (m)

```{R sitesbyElev,eval=FALSE}
diat_el <- get_sites(altmin=100, altmax=120)
```

Example of getting datasets for sites between minimum and maximum elevations 

```{R getSitesByElevExample}
diat_el <- get_sites(altmin=5000,altmax=5500) #Will need to look over at a later time 
diat_el2 <- get_datasets(datasetid= diat_el)
```



### Investigator name / person name
```{R Diatom Investigator}
Contact <- get_contact(contactname = 'X')

```
Example of returning a contact id given the contact name
```{R Diatom Investigator name}
Don <- get_contact(contactname = 'Donald F. Charles')
```

### Within or intersecting a specified time interval 
```{R Diatom Time Interval,eval=FALSE}
 

```
Example
```{R}
Interval <- filter(X, age_ad >= 1950)

```

### Taxon name or ID 
```{R getTaxa}
diat_nm<- get_dataset(datasettype = 'diatom',taxonname = 'Navicula minima')
diat_nm1<- get_dataset(datasettype = 'diatom',taxonids = 11249)
diat_taxa <- get_tables('Taxa')
#To access the diatom taxa table use get_tables('Taxa'), Taxon name and Taxon ID can be used to find taxa by dataset types
```

### Submission date
```{r SubDate}
subdate <- get_datasets(subdate= "04-05-2016")
subdate <- get_dataset(subdate= 2016-04-04)
#Date of dataset submission, either YYYY-MM-DD or MM-DD-YYYY. 
#SIMON The above code does not work.
```

### Dataset DOI

```{r getDiatomsByDOI}
neDiatoms <- get_datasets(dois=c(...)) # basic format
neDiatoms <- get_datasets(dois=c(43516, 43519, 46228)) # Example using DOI's for Livingston P, West P and Wolf L in the Adirondack Mountains, NY.
#JERRIN / SIMON - This code chunk does not work.  Is the DOI function still being developed?
#Jerrin: I think it may have to with there being 3 dataset IDS not complying with the code and maybe that it is not ready yet. 
```

### Collection unit type, ID or Handle [secondary]
Code to retreive datasets by collection type - usually would be one part of a larger code chunk or function

```{R diatombyColltype,eval=FALSE}
Col<- get_datasets(CollType='Core')
# SIMON/SOCORRO codes doesn't work for collection units  
```

Example of getting dataset by Collection Type id
```{R sitesByCollTypeMult,eval=FALSE}
get_dataset(CollType='Core','section')
```

```{R sitesByCollID,eval=FALSE}
get_dataset(CollUnitID='')
#CollUnitID Unique database record identifier for the collection unit.
```

```{R sitesByCollUnitHandle,eval=FALSE}
get_dataset(CollUnitHandle='')

#CollUnitHandle	Code name of the Collection Unit with which the dataset is associated. This code may be up to 10 characters. Data are frequently distributed by Collection Unit, and the Handle is used for file names.
```

### Constituent database
JERRIN / SIMON - Code needs to be added
```{R SitesbyConDB}
consDB <- get_
```

Example of finding constituent databases

```{R SitesbyConDBExample}
ConDB <- 
```

### Sample keyword [secondary]
Code to retreive datasets by keyword - usually would be one part of a larger code chunk or function
```{R SitesbyKW}
get_dataset(search('x'))
```

Example of using the search function returning keywords 
```{R}
get_dataset(search('modern'))# Search could find so maybe
```



### Aggregate dataset(s)
Get dataset IDs of all members of an aggregate dataset
Also, get_datasets and get-downloads
```{R Diatom Aggregate Dataset}
library(neotoma)
library(neotoma2)
aggr_set <- read.csv()# If we are going to use the excel file we should read it in here and than could use it to find information
<- get_datasets()
<- get_download()
#General guideline steps when we do get info to use for other purposes 


```
Example
```{R Diatom Aggregate Dataset Example}

```

### Publications
Get all dataset IDs associated with a particular publication
  Soccorro is working on this
```{R Diatom Publication}
diat_pub <- get_datasets()
```
Example - [not sure what this code does...]
```{R Diatom Publication example}
diat <- get_datasets()
diat_pub <- get_publication()
pub_diat <- sapply(diat_pub, 
                 function(x) {
                   x$pi.data$ContactID
                   })
```
### Water chemistry
#### Is water chemistry available?  If so, which parameters?
Determine if any water chemistry data is available for one or more sites or diatom datasets for those sites
If chem data are available, which parameters? (List variables included) 

#### From sites within range of water chemistry characteristics
Get datasets associated with water chemistry within a specific range (e.g., pH between 6 and 8)
Why is following code chunk here?

```{r getWaterChem,}
neDiatoms <- get_datasets(datasettype="diatom surface sample", loc=BOUNDING BOX)
```

Example of how to get water chemistry from the different dataset types

```{r getWaterChemEX}
diatomss <- get_datasets(datasettype = 'diatom surface sample') %>% 
  get_downloads()

waterchem <- get_datasets(datasettype = 'water chemistry') %>% 
  get_downloads() %>% 
  filter(pH < 5)

diatomss <- get_aggregate(123)
waterss <- get_aggregate(124)

diatomdl <- get_downloads(diatomss) %>% compile_downloads()
waterdl <- get_downloads(waterss) %>% compile_downloads()

# This would take two sets of sites, datasets or downloads and
# order them in the right order.
aligned <- align_sites(diatomss, waterss)
```

```{r fixing}
diatomss<- get_dataset(datasettype = 'diatom surface sample')
waterss<- get_datasets(datasettype = 'water chemistry')
diatom<- get_dataset(datasettype = 'diatom')
#Sapplyy function is used to return diatomss, read / extract the metadata and select dataset IDs for the first 20 lakes 
subsetss <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]
#Sapplyy function is used to return diatom, read / extract the metadata and select dataset IDs for the first 20 lakes 
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') # It returns the file that is used 
} else {
  diat_dl <- get_download(subset)
  diat_dlss <- get_download(subsetss)
  diat_dl <- bind(diat_dl, diat_dlss)
  saveRDS(diat_dl, 'filename') # It saves this as an object of the download with file
#  Where is "filename"saved? - What directory? - type getwd() in the console to find out where the file is.
}
```



#### From sites where one or more specified water chemistry characteristics were measured
```{R Diatom Multiple Water Chemistry}
diatomwch<- get_dataset(datasettype = 'water chemistry')
diatom<- get_dataset(datasettype = 'diatom surface sample')

subsetwch <- sapply(diatomwch, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('fileWCH' %in% list.files()) {
  diat_dl <- readRDS('fileWCH') # It returns the file that is used 
} else 
  diat_wch <- get_download(subsetwch)
  diat_dls <- get_download(subset)
  diat_dlb <- bind(diat_wch, diat_dls)
  saveRDS(diat_dlb, 'fileWCH')
  
  wideWCH <- compile_downloads(diat_dlb) 
## neotoma function converts multiple downloads into single object 
minWCH <- wideWCH %>% 
  group_by(dataset) %>% #dataset was returned from the table 
  summarise(min(depth)) #dplyr function to create a dataframe
  
wideWCH %>% filter(is.na(depth))

```



### Diatom Sample analyst name
Get all datasets associated with name of a sample analyst
Currently seems to just get a list of people who analyzed surface samples
Needs to be able to accept contact ID of a specific person
```{R Diatom Sample Analyst}
Con_<- get_dataset
Contact_diat <- get_dataset(datasettype = 'diatom')

Analyst <- sapply(Contact_diat, 
                 function(x) {
                   x$pi.data$
                   })
```
Example
```{R Diatom Sample Analyst example}

```


### Diatom taxa
#### Diatom counts include one or more specified diatom taxa
Code does not include possibility of specifying a particular diatom taxon
```{R datasetByTaxa}
 'diatom')
diat_dl <- get_download(diatoms)
diat_taxa <- taxa(diat.dl)
```

Example of getting  the downloads of a datasettype 

```{R datasetByTaxaExample}
diatoms<- get_dataset(datasettype = 'diatoms')
diat_dl <- get_download(diatoms)
diat_taxa <- taxa(diat.dl)
```


#### Diatom counts include only taxa with abundance greater than x percent (in sample or core)

```{R Diatom Counts}

```

Example

```{R Diatom Counts EX}

```

### Site characteristics
#### Site area larger or smaller than specified size

```{R Diatom Site Area}

```

Example

```{R Diatom Site Area EX}

```

### Depository in which diatom slides are located

```{R Depository}
diat.data <- get_dataset(datasettype='diatom') # access to neotoma explorer but needs to specify 
browse(diat.data)
```

Example
```{R Depository EX}
library(neotoma)
```
### Chronology
Does a dataset have an associated chronology?  If so, what are metadata (e.g., upper and lower age bounds)?
  Not sure of purpose of the following code
```{R Chron }
get_chroncontrol('x')# Can be thought like how bacon model is run through R
```
Example
```{R AnotherChronExample}

```
#### Chronology (y/n) and characteristics
```{R Chronology}
<-get_chroncontrol(x) # Need to check if this relates to chronology or bacon 
```

Example
```{R ChronologyExample}

```


### Format for browsing using multiple criteria - Examples 
Examples: [could get complicated]  General rules and tips.  [Add as they become known]

#### Find all diatom datasets of any datatype

#### Find all diatom datasets of any datatype within a geographic region

#### Find all diatom surface sample datasets within a geographic region

#### Find datasets .... with surface area larger than x ha .......

### Other options / Misc:




## Create output of browse results 
Minimum “list” of dataset, collection, and / analysis unit ids for further browsing and use as input to other R functions. 
 
Standard comprehensive output file for use in detailed browsing. Variables should include all of the following (variables are grouped by their location on Tilia tabs): 
  1.  Site information: Site ID, Site name, Latitude, Longitude, Latitude width, Longitude width, Country, State, County, Admin Unit (3rd Geographic Unit), Lake characteristics, publication id
  2. Collection unit information:  CU ID, Type, Collection unit name, Collection unit handle, Location in site, Collection device, Date collected, Water depth of collection
  3.  Dataset information: Data Type (Diatom, Diatom surface sample, or Diatom top-bottom), Primary publication, Investigators [or first author of publication], Sample analyst


# Create output files for data analysis

The create data output files section -  standard formats for diatom counts, metadata, chronology, water chemistry.  It provides examples for retrieving data and creating output files in a few basic formats.  Formats include those that can be used as input to data analysis programs - R packages and others.  In general, they should include all related data; the amount of data can be reduced later.They will include several descriptive variables and be easily readable. [input to code chunks can include output from browse tasks]

## Basic files / matrices

### Diatom counts
- single sites and multiple sites; aggregate data set; stratigraphic vs surface sample vs top-bottom; percentages vs raw counts.

#### Create a count data file for a single site
JERRIN / SIMON - code does not run - "Error in get_dataset.default(schrader) : siteid must be numeric."
```{r get_singleSitebyName}
schrader <- get_sites(sitename = 'Schrader Pond') # % can be used to approximate sitenames
schrader.data <- get_datasets(schrader)
schrader.dl <- get_download(schrader.data)
schrader.cnt <- counts(schrader.dl)
sapply(schrader.cnt, dim) 
print(schrader.dl)
```

EXAMPLE TESTING OF FILTERING 
```{R UpperWallfaceEXAMPLE}
uwallface <-get_site('Upper Wallface%') 
uwall <- get_dataset(32252) # diatom datasetid for UWall is 32252
uwallface.dl <- get_download(uwall)
## Sapplyy function is used to return diatomss and with the function it is reading the metadata and selectind dataset,id to query from first 20 lakes 
#### JERRIN Review this example with me
subsetUWall <- sapply(uwall, 
                   function(x) {
                     x$dataset.meta$dataset.id
                   })

if('UWall' %in% list.files()) {
  UWa_dl <- readRDS('UWall') # It returns the file that is used 
} else {
  UWallf_dl <- get_download(subsetUWall)
  saveRDS(UWallf_dl, 'UWall') # It saves this as an object of the download with file
}

wideCounts <- compile_downloads(UWallf_dl) 
## neotoma function converts multiple downloads into single object 
minRow <- wideCounts %>% 
  group_by(dataset) %>% #dataset was returned from the table 
  summarise(min(depth)) #dplyr function to create a dataframe
  
wideCounts %>% filter(!is.na(Eunotia.diodon))
## dplyr function used to subset a data frame
diat_taxa <- taxa(UWallf_dl)
```
Upper Wallface Pond examples
```{R Upper Wallface EX}
library (neotoma)
### Find Neotoma Site Id for Upper Wallface Pond 
uwallface <- get_site (sitename = "Upper Wallface%")
### Find datasets and IDs associated with U Wallface Pond
uwallface.dl<- get_dataset(uwallface)  # Review datasets available note ID of the one of interest
### download data for diatom core dataset (Dataset 32252)
uwallface.dw <- get_download (32252)
### Get diatom counts for dataset 32252
uwallface.ct <- counts (uwallface.dw)
### Find the number of intervals and number of taxa in a count
sapply(uwallface.ct, dim)
### Look at the matrix of diatom counts
glimpse (uwallface.ct)
str(uwallface.dw) # str is a useful function to see the overall data structure for a dataset 
Comp_UWall <- compile_downloads(uwallface.dw) # used for formatting into a table 
write_xlsx(uwallface.ct,  ".xlsx")

```

```{R Upper Wallface View counts}
### View sample metadata, list of taxa, and counts in Download dataframes 
### View sample metadata,
uwallface.dw[["32252"]][["sample.meta"]] 
### View taxa list
uwallface.dw[["32252"]][["taxon.list"]]
### View diatom counts
uwallface.dw[["32252"]][["counts"]]
### View Chronology
uwallface.dw[["32252"]][["chronologies"]]
```

#### Get count data for a diatom surface sample
Get data from from all datasets of "diatom" and diatom surface sample dataset types
Example of getting surface sample through filtering and usng multiple data set types to get metadata
Note: similar code for getting output of water chmistry data is below, around line 350
```{R datasetByTaxa with DBT}
## Simon Edited this:
diatomss<- get_dataset(datasettype = 'diatom surface sample')
diatom<- get_dataset(datasettype = 'diatom')
#SIMON - "diatom top-bottom" needs to be added as a choice for datasettype.
#Sapplyy function is used to return diatomss and with the function it is reading the metadata and selecting dataset,id to query from first 20 lakes 
subsetss <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id 
                   })[1:20]
#In the subsets it would go through each dataset to match the search of the metadata location 
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') # It returns the file that is used 
} else {
  diat_dl <- get_download(subset)
  diat_dlss <- get_download(subsetss)
  diat_dl <- setdiff(diat_dl, diat_dlss)
  saveRDS(diat_dl, 'filename') # It saves this as an object of the download with file
}

wideCounts <- compile_downloads(diat_dl) 
#neotoma function converts multiple downloads into a single object 
minRow <- wideCounts %>% 
  group_by(dataset) %>% #dataset was returned from the table 
  summarise(min(depth)) #dplyr function to create a dataframe 
#Overall count data is retrieved from this portion 
wideCounts %>% filter(!is.na(Cornus)) # SIMON this line does not work 
#dplyr function used to subset a data frame
diat_taxa <- taxa(diat_dl)# The function taxa returns a data frame of taxa for an (object)
```

 

Example of using get_dataset to get diatom top-bottom samples (currently not usable since Top-Bottom not in package)
```{R datasetByTB,eval=FALSE}
library(neotoma)
diatomss<- get_dataset(datasettype = 'diatom top-bottom') # top-bottom not a dataset yet
diatom<- get_dataset(datasettype = 'diatom')
#Sapplyy function is used to return diatomss and with the function it is reading the metadata and select in dataset,id to query from first 20 lakes 
subsettb <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id # Location of the data
                   })[1:20]
#In the subsets it would go through each dataset to match the search of the metadata location
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') 
} else {
  diat_dl <- get_download(subset)
  diat_dltb <- get_download(subsettb)
  diat_dl <- bind(diat_dl, diat_dltb)
  saveRDS(diat_dl, 'filename')
}
#It would return results of the top-bottom to bind them and present in a table format 
```


### List of diatom taxa 
- with name, authority, code, notes, etc.
```{R, diatom taxa out}
get_table(taxa)
get_taxa()
compile_taxa
```
Example of returning taxa 
(IN PROGRESS)
```{R ListTaxaExample}
get_dataset(taxonids = )
get_dataset(datasettype = 'Diatom',taxonname = 'x')
```
```{R Upper Wallface EX}
library (neotoma)
### Find Neotoma Site Id for Upper Wallface Pond 
uwallface <- get_site (sitename = "Upper Wallface%")
### Find datasets and IDs associated with U Wallface Pond
uwallface.dl<- get_dataset(uwallface)  # Review datasets available note ID of the one of interest
### download data for diatom core dataset (Dataset 32252)
uwallface.dw <- get_download (32252)
### Get diatom counts for dataset 32252
uwallface.ct <- counts (uwallface.dw)
### Find the number of intervals and number of taxa in a count
sapply(uwallface.ct, dim)
### Look at the matrix of diatom counts
glimpse (uwallface.ct)
str(uwallface.dw) # str is a useful function to see the overall data structure for a dataset 
Comp_UWall <- compile_downloads(uwallface.dw) # used for formatting into a table 
write_xlsx(uwallface.ct,  ".xlsx")

```
## Site information and environ data

### Water chemistry
```{R WCHM Out}
get_dataset(sitename='x',datasettype = 'diatom')
```
Example
```{R ChemistryExample}

```
### Chronology


### Metadata - various options
```{R Metadata}
get_download()# Options within diatoms to organize it 
get_dataset()
```
Example
```{R DownloadStuffExample}
get_download()
get_dataset()
```

### Other types of data 
- LOI, geochemistry
```{R ETC}
get_dataset(datasettype="")
```
Example
```{R ETC EX}
get_dataset(siteid=,)
```


Issues:  Put metadata in the same files as the data matrices?  How to combine related files (e.g., diatom counts and chronology)? [When is it best to convert diatom counts to percentages?]

## Input files for data analysis programs
  Some programs have no standard input format
### Bacon, ### Vegan, ### Rioja, ### Tidypaleo
### Others 

#Make plots and maps 
(e.g., stratigraphic diagrams, maps of taxa distributions)

```{r plot}
library(leaflet)
test <- c(44764, 44765, 44766)
all_wi <- neotoma::get_dataset(test, datasettype = "diatom")
# We're going to use this multiple times I think, so let's make it a function:
leaflet_map <- function(dataset_in) {
  dataset_summary <- do.call(rbind, lapply(dataset_in, 
                        function(x){
                          # here we pull out the site information from the `dataset` objects:
                          data.frame(name = x$site.data$site.name,
                                     lat  = x$site.data$lat + runif(1, -0.005, 0.005),
                                     long = x$site.data$long + runif(1, -0.005, 0.005),
                                     type = x$dataset.meta$dataset.type)
                        }))
  # The leaflet package documentation uses piping.  For the sake of this tutorial, I won't.
  # First, define a color palette for the dataset type symbol plotting.
  pal <- colorFactor("Dark2", domain = levels(dataset_summary$type))
  # Now make the leaflet map, add base raster tiles and then add the markers for the records:
  map <- leaflet(data = dataset_summary)
  map <- leaflet::addTiles(map)
  map <- leaflet::addCircleMarkers(map, ~long, ~lat, 
                                   popup = ~paste0("Site: ", as.character(name), "<br>",
                                                   "Type: ", 
                                                   as.character(dataset_summary$type)),
                                   color = ~pal(type),
                                   stroke = FALSE, fillOpacity = 0.5)
  # You need to explicitly call the `map` object to make it appear!
  map
}
# Since that's all wrapped in a function, we can all it with any `dataset_list`:
leaflet_map(all_wi)
```



###Plot of the abundance of multiple diatom taxa 
for a single core - vs depth or time
###Plot of abundance of a single taxon 
for cores from multiple sites - vs time
### Plot of abundance of a taxon vs an environmental characteristic 
(e.g., water chemistry variable)
### Map of distribution of sites 
For example, that are part of an aggregate dataset; GGPlot, Leaflet

### Map of distribution of a diatom taxon
; symbol size related to % abundance

#Modify and analyze data 
- and other miscellaneous tasks
## Add to or modify data in Neotoma

### Add aggregate datasets to Neotoma

### Create new ecological groups and assign taxa to the groups
```{R set taxa}
set_taxa('x') # Not code but could be something

Example
```{R set taxa ex}

```

### Add to a table that explicitly matches water chemistry and diatom datasets
This is especially important for cases where sites were sampled for water chemistry as part of more than one study.

## Extract a list of publications for a set of datasets
```{R get pub out}
<- get_publications(datasetid= x)
### JERRIN - review following example with me
### So it would involve contact name/ID, publication ID, datasets having publication  
```

## Extract a list of DOI’s for a set of datasets
```{R DOIS}
get_publications(datasetid=)# Not code seems to need to be a mix of get_dataset and get_publications
```
Example
```{R DOIS EX}

```

## Add standard sets of diatom taxa names that could be used to convert multiple synonyms to another set of names
```{R standard set}
get_dataset(taxonname = ,search())
```

# Create Output files
The following items will be moved to corresponding topics in the outline above
## Diatom counts
SIMON ASSISTED EXAMPLE [Example provided by Simon Goring - date]
Creates file with diatom counts for surface samples 
```{R datasetByTaxa from Simon}
library(dplyr)
library(purrr)
# Get diatom datasets (Diatom and Diatom Surface Sample data types) for all sites in the northeast US, defined as a set of states.
gpids <- c(8412, 7990, 7934, 7326, 7923, 8981, 6442, 7368)

ne_diatom <- map(gpids, function(x)
  neotoma:::get_dataset(gpid = x,datasettype="diatom")) %>%
  neotoma::bind()   
  
ne_diatomSS <- map(gpids, function(x)
  neotoma:::get_dataset(gpid = x,datasettype="diatom surface sample"))%>% 
  neotoma::bind() 
ne_dataset<-bind(ne_diatom,ne_diatomSS)


if('DiatomFil' %in% list.files()) {
  Diatom_dl <- readRDS('DiatomFil') 
} else {

  allDatasets <- list()
  
  for(i in length(allDatasets):length(ne_dataset)) {
    allDatasets[[i]] <- get_download(ne_dataset[[i]])
  }
  
  ne_download <- neotoma::bind(allDatasets)
  
  saveRDS(ne_download, 'DiatomFil')
}

# Create diatom count files
wideCounts <- compile_downloads(Diatom_dl) 
minRow <- wideCounts %>% 
  group_by(dataset) %>% 
  summarise(min(depth)) 
```

Jerrin Example of using just dataset ID
### Example similar to above but starting with a set of dataset ID's
```{R ExampleDataset}
library(purrr)
V1 <-c(44786,44787,44788)
#In this example we take these 3 sites with combine function 
V1_diatom <- map(V1, function(x)
  neotoma:::get_dataset(x,datasettype="diatom")) %>%
  neotoma::bind()   
#In the get_dataset line, whatever is in the parenthesis is a parameter such as x or gpid in which it will take from V1 since it was stated in the line above it

if('V1' %in% list.files()) {
  V1_dl <- readRDS('V1') 
} else {

  V1Datasets <- list()
  #
  for(i in 1:length(V1_diatom)) {
    V1Datasets[[i]] <- get_download(V1_diatom[[i]])
  }
  #For loop will being going through each step to first create the file and go through each site with the download
  V1_download <- neotoma::bind(V1Datasets)
  
  saveRDS(V1_download, 'V1')
}
V1Counts <- compile_downloads(V1_download) 
V1Row <- V1Counts %>% 
  group_by(dataset) %>% 
  summarise(min(depth))
write_xlsx(V1Counts,  ".xlsx")

#This last step is the way to create a table which can be written as csv to export out 

```

Example of getting information for a single site ID using get_dataset with subsets to return counts.  Created by Simon Goring
add comments
```{R ExampleSingleSite }
Mirror<- get_dataset(39813) # Dataset ID for Mirror Lake, Newer dataset/ site ids does not seem to work 
subsetda <- sapply(Mirror, 
                 function(x) {
                   x$dataset.meta$dataset.id 
                   })
# The subset is not a function but a way to filter the dataset to get the portions of interest and sapply is from R package  
if('Mirror' %in% list.files()) {
  diat_da <- readRDS('Mirror') 
} else {
  diat_dla <- get_download(subsetda)
  saveRDS(diat_dla, 'Mirror')
}
#In the if and else loops they work together that a file will be created and download the data from the subset
diatCount <- compile_downloads(diat_da) 
minimumRow <- diatCount %>% 
  group_by(dataset) %>% 
   summarise(min(depth))
#In compiling downloads it displays the information in a table format and could be organized with group_by and summarise function
```





