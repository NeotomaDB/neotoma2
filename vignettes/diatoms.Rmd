---
title: "Working with diatom data in the `neotoma2` R package"
output:
  rmarkdown::html_vignette: default
  html_vignette:
    toc: yes
    toc_depth: 4
vignette: |
  %\VignetteIndexEntry{Working with diatom data in the neotoma2 R package} %\VignetteEngine{knitr::rmarkdown} %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup}
library(neotoma2)
library(neotoma)
library(dplyr)
library(purrr)
library(sf)
```

## Introduction

This document provides general guidance and specific code examples for those wanting to use `neotoma2` to retrieve and work with diatom data from the Neotoma Paleoecology Database.  This vignette, as part of the `neotoma2` package, also provides the package developers (Socorro Dominguez and Simon Goring) a set of  structured descriptions for the kinds of work that diatom researchers may wish to perform with Neotoma data, and some of the specific tasks they may wish to accomplish.  Researchers who would like to add examples, or other workflows can reach out to the developers through [GitHub Issues](https://github.com/NeotomaDB/neotoma2/issues), or the [Neotoma Slack Workspace](https://join.slack.com/t/neotomadb/shared_invite/zt-cvsv53ep-wjGeCTkq7IhP6eUNA9NxYQ).

Some code in this document was borrowed from the `neotoma2` markdown document prepared by Simon Goring and Socorro Dominguez and the original Neotoma R package ([Goring et al. 2015](http://doi.org/10.5334/oq.ab)).

One of the main goals of `neotoma2` is to pull records out of the Neotoma database and into a user's R workflow.  This will help diatomists and environmental scientists produce clear working documents that use data from Neotoma, and allow them to combine it with their own data or data from other sources.

> If you’re thinking without writing, you only think you’re thinking. — *Leslie Lamport*

This document is organized to address two main goals of users, to browse the database to discover datasets that meet specified criteria, and to create output files that can be used for further analysis.  Other goals are to create plots and maps and to analyze data using R code.

### Why `neotoma2` and not just an update of `neotoma`?

The Neotoma servers and all the back-end services recently [Simon - add month / year] migrated from a SQL Server Database on a lonely Windows N95 computer to a more robust server and set of services.  Because of this migration, a large number of the tools we use to access data are no longer accessible.  For this reason, we [Simon - Neotoma IT Team?] made the choice to create a new package.  This is because code that is run using `neotoma` will not be directly comparable to code using `neotoma2`, since data objects and expected behaviours will be different.

### Data Organization in Neotoma

It's worth knowing a bit about how the Neotoma database is organized, and what we mean when we talk about things like "sites", "datasets" and "samples".  The database itself is a Postgres database.  People who are comfortable with SQL can download a snapshot of the database and run much of the analysis on their own.

#### What does the data look like?

The Neotoma data model is available online at the [Database Schema](https://open.neotomadb.org/dbschema) page. As of September 2021,there were 150 different tables that store data for the database.  Some of these have particular kinds of data (for example, `agetypes`), some of these link tables together. The `neotoma2` package supports access to some tables directly, but not all.  For specialized cases a user may be required to directly access an entire table (using the `get_table()` function).

#### Sites, Datasets, etcetera

Neotoma data is structured spatially.  Each sample location is assigned a **site**.  A site is a spatial location, defined by either a point or a polygon.  It may be a lake, an archaeological site, a swamp, or some other location.

Within a **site** there may be one or more **collection units**.  
A collection unit represents the material (e.g., sediment core) that was removed from a specific location within a site (e.g., a lake).  So, a researcher may have taken multiple cores within a lake basin, or an archaeologist may have several dig sites within a larger area.  Collection unit material is subdivided into **analysis units** (e.g., sediment intervals within a core). **Samples** can be removed from analysis units and analyzed for a particular dataset type (e.g., diatoms, pollen, water chemistry).  Groups of analysis units [samples??] from an individual collection unit are then grouped into a **dataset**.

#### What is the R package doing?

When you work with the `neotoma2` package you are working with data from the database, but it is mediated through R functions (like `get_sites()` to get site information) that themselves call public URLs, that are basically abstractions of database calls.  So, for example:

```r
get_sites(siteid=12)
```
actually calls out to the internet for the result at:
```
https://api.neotomadb.org/v2.0/data/sites/12
```
Which itself calls an SQL query:

```sql
SELECT * FROM ndb.sites
WHERE siteid = 12
```

So, for most users, it's a lot easier to just use the R functions, since they create objects in R that work with other commands and any statistical analysis you might want to do.

#### Functions in `neotoma` and `neotoma2`
Following are descriptions of the main functions in `neotoma` and `neotoma2`. See package documentation for more details.

`neotoma2` was being developed while this vignette documentation was being prepared, so not all the original package functions were available.  Currently, some functions from both `neotoma` and `neotoma2` are used in this document.  Over time, original package functions should be replaced with corresponding `neotoma2` functions. In the code chunks below, `neotoma::` is used to refer to functions in the original neotoma R package, for example, **`neotoma::`**`get_site(whatever)`.

##### `neotoma` functions
###### get_site
Usage: Sites can be searched using the following supported parameters, e.g., get_sites("Sitename"):

| parameter | allowed values |
| ------ | ------- |
| `siteid` | integers (values > 0) |
| `sitename` | valid character string; `%` as wildcard |
| `altmax` | integers (values >= than `altmin`) |
| `altmin` | integers |
| `loc` | spatial coordinates (WKT or geoJSON) |
| `limit` | integer > 0; default 25 |
| `offset` | integer > 0; default 0 |
[[Simon - Provide reference for description and use of "limit" and "offset"]]

Values returned: A dataframe that includes: siteid, sitename, long [mean], lat [mean], elev, description, long_acc [width of bounding box], and lat_acc [height of bounding box]

###### get_dataset
Usage: get_dataset(x, datasettype, piid, altmin, altmax, loc, gpid, taxonids,taxonname, ageold, ageyoung, ageof, subdate)

x can be an "optional value, either a numeric site ID or object of class download, download_list or site."

Values returned for each dataset:  datast.id, dataset.name, Coll Unit Handle, Coll Unit Name, Coll Type, Dataset Type, AgeOldest, AgeYoungest, (Sub)mission Date(s), Dataset PIs, Site (object with site variables)
  
###### get_download
"Using the dataset ID, site object or dataset object, return all records associated with the data as a download_list.

Usage:  get_download(x, verbose = TRUE)"
Arguments:x can be a "single numeric dataset ID or a vector of numeric dataset IDs as returned by get_datasets, or a site, dataset, or dataset_list; verbose, logical - should messages on API call be printed?"

Values returned; "an object of class download_list, containing a set of download objects, each with relevant assemblage information and metadata: The download object is a list of lists and data frames that describe an assemblage, the constituent taxa, the chronology, site and PIs who contributed the data. The following are important components:" dataset, sample.meta, taxon list, counts, lab.data, chronologies"

##### `neotoma2` functions - [To be added]
###### get_sites
###### get_datasets
###### get_downloads

## Browsing - Data discovery

This section describes ways of searching the Neotoma database for sites and diatom datasets using a variety of criteria, either alone or in combination.  Criteria include those also available in Neotoma Explorer, plus several more. Examples include options for viewing and saving output results. The primary purpose of each code chunk in this section is to find the sites or datasetids for datasets that meet the criteria specified in the code.  The sets of IDs that are returned can then be used as input to other code chunks that return more detailed information on the datasets and create output files for data analysis (e.g., diatom counts).

     Find sites section - makes use of the get_site() or get sites() functions
     Find dataset sections
         Basic - uses only the get_dataset() or get_datasets() functions
         Complex - uses the above plus other functions

### Find sites (using get_site)

[Include brief explanation of differences between Neotoma R and Neotoma R2 ??.  Use R2!! Neotoma R@ get_sites is working (totally?  altitude issues??) and provides more information than get_site.  Therefore, there is no reason to use original R.]

We can search for information on a single or multiple sites.  Sometimes it is useful to find locations of all sites within a region, whether or not they are diatom sites.  This can give us an indication of the level of paleoecological 'effort' in a region.  We can often use a site search to do some preliminary work, since the `site` object that `neotoma2` returns contains less information than the larger `dataset` or `download` objects, that contain full metadata.  We might want to generate a map of all sites, and superimpose specific sites we are interested in, for example.

#### Site Name

If we know the names of one or more of the existing sites that we are looking for, we can get site data using the `sitename` parameter.

Get data on a single site using sitename

```{r sitesbyName example}
# diat <- get_sites(sitename = "")  # Basic format
diat <- get_sites(sitename = 'Schrader Pond')  # Example
diat <- get_sites(sitename = '%Schra%')      # Example using wildcards (%)
diat
```
Get data on multiple sites using sitenames.
[Simon / Soccorro - the following code does not return the correct results]
```{r multsitesbySitename example}
# Join a list of site names together using the combine command, c()
sitenameList <- c("Bald Hill", "Blake (sutton)", 
                  "High (sudbry)", "Holland", 
                  "Little Hosmer", "Long (grnsbo)", 
                  "Long (shefld)", "Round (shefld)")
sitenameList
aa <- sitenameList %>% 
  map(function(x) get_sites(sitenameList = x))
aa

```

Get data on multiple sites using sitenames - National Lakes Assessment Example

```{r NLA}
library(neotoma)
library(neotoma2)
# Join a list of site names together using the combine command, c()
nlaxl <- c("Gardner Pond","George Wyth Lake","Goose Pond","Gorton Pond","Grassy Pond","Green Belt Lake","Grimes","Grist Millpond","Grittman Lake","Groton Reservoir","Half Moon Lake","Halfway Pond","Hannaberry Lake","Harper Lake","Haskell Lake","Heggs","Henry's Lake","Hert Lake","Highland Lake","Hi-Land Lake","Hinkley's Pond","Horsfall Lake","Hosmer Lake")
nla_sites <- c() 
# Run a loop that gets sites for each name in the object containing lake names (nlaxl)
for(name in nlaxl){
sites <- get_site(sitename = name)
nla_sites <- c(nla_sites, sites)}  # The object nla-sites now contains the get_sites results for all lakes listed in nlaxl
nla_sites
```

#### Site ID
Find sites using siteid.  In the following code chunks, we assume that siteids have been obtained using Neotoma Explorer, from Neotoma Landing Pages or from an external file.

Get data on a single site using siteid
```{r sitesbySiteID example}
# diat_3<-get_sites(siteid= x) # basic format
diat_4<-get_sites(siteid= 27408) # Example for single site (Schrader Pond)
#The get_site function will return basic metadata, e.g.,  sitename,location and collection unit
diat_4
```

Get data on multiple sites by using siteids.
[Simon and Soccorro - the following code chunk does not work]

| `sitename` |  `siteid` |
| -- | -- |
| Jackson Pond | 25918 |
| Jellison Hill Pond | 25919 |
| Jimmie Pond | 25920 |
Get data on a multiple sites by using siteids
```{r multsitesbySiteIDs example}
siteids <- c(25918,25919,25920)
diat_6 <- get_sites(siteid = siteids)
```
Get data on multiple sites by reading a text file of siteids

The above code returns data for three sites.  We could use a larger set of site IDs either by loading the IDs from a file, or by entering them directly.  Here we assume that there exists a file called `NLAD.txt` with a list of site IDs in a plain text file for the National Lakes Assessment.  The contents of the file look like this (the ellipsis would be replaced by other numbers):

```
8556
10427
13527
23249
23250
...
24214
23264
23265
```

There may well be many more lines with numbers representing each site identifer in the set of records.  In this case we would load the data like so.:


```{r NLAmultiplesiteID, eval=FALSE}
nlad <- read.table('NLAD.txt', header=FALSE)
nlaSites <- get_sites(nlad)
#This code assumes that the text file is located in your working directory, which can be found with getwd()
```
#### Geographic location

Find all sites located in a geopolitical unit as specified by a gpid
```{r get site by gpid}
# diat_1<-get_site(gpid = x) # basic format
diat_1<-get_site(gpid = 6198) # Example using geopolitical ID for Alaska. The gpid for Alaska was retrieved from the GeoPoliticalUnits table 
diat_1
```

View the geopolitical table to search for locations and gpids.

A gpid is useful way to specify country and state boundaries.
The code below will open the Geopolitical units table.  Once the table appears, use the search function at top to find for the name of a geopolitical unit of interest and its corresponding gpid 

```{r getGeoPolUnits}
gpids <- neotoma::get_table(table.name='GeoPoliticalUnits')
gpids
 
```

Example - get sites from multiple geopolitical units (e.g., states)
```{r retrieveByGeopol}
library(dplyr)
library(purrr)

gpids <- c(8412, 7990, 7934, 7326, 7923, 8981, 6442, 7368)
ne_sites <- map(gpids, function(x)
  neotoma:::get_site(gpid = x)) %>%
  neotoma::bind()
ne_down <- neotoma::get_download(ne_sites)
# The gpids were obtained from the Geopolitical units table 
# The code will run get_site for each gpid, then will bind the results, and then downloaded data
```
Find all sites within a user-specified spatial polygon

We can use the `sf` package to create polygons for spatial searches (the package also allows you to pass in geoJSON or WKT spatial objects).  In the example below, we first create a matrix to represent the corners of a bounding box of the northeastern United States. We then create a spatial polygon ("neus") based on the co-ordinates.  Finally, we to use "neus" as input to the `get_sites()` function.

```{R siteSpatialSearch, eval = FALSE}

northeastUS <- rbind(c(-80,40), c(-80,48), 
                     c(-65,48), c(-65,40), c(-80,40))

neus <- sf::st_polygon(list(northeastUS))

neUSsites <- get_sites(loc = neus)
``` 

#### Elevation
Find sites between minimum and maximum elevations 

```{R sitesbyElev,eval=FALSE}
diat_el <- get_sites(altmin=100, altmax=120)
```

### Find datasets (using get_dataset)
#### Dataset ID
<<<<<<< HEAD
Get meta data on a single dataset using datasetID 

```{r get datasetID}
# diat_ID <- get_dataset(datasetid) - basic format
library(neotoma)
diat_ID <- get_dataset(44764) # Example
diat_ID
diat_dow <- get_download(diat_ID)
#browse (44764) [Simon - opens Neotoma Explorer, but does not go to the site specified]
# [Following line of code is for get_downloads.  Perhaps better to add it to the downloads section of this document.]
diat_comp<- compile_downloads(diat_dow)
diat_comp
#get_dataset could use site id or dataset id  to return information on site, metadata, publication, and date submitted 
```
Get data on multiple datasets using multiple dataset IDs 
```{r multdatsetid }
library(WriteXLS)
multid <- c(44764,44765,44766)
diat_multid <- get_dataset(multid) # Example
diat_down <- get_download(diat_multid)
diat_tab <-compile_downloads(diat_down)

WriteXLS(diat_tab, "R_datasets.xlsx") # can also save as .xls file
getwd() # shows path to working directory, where .xlsx file is saved
#Multiple dataset ids combined to put in a object will run get_dataset so less code needs to be created 
```

Get Sample IDs for Dataset IDs
```{r GETSampleID for Dataset ID}
CODE <-c(44764,44765,44766)
C1<- get_dataset(CODE)
CD <- get_download(C1)
C2 <- sapply(CD, 
                 function(x) {
                   x$sample.meta$sample.id
                   })
C3 <-sapply(CD, 
                 function(x) {
                    x$dataset$dataset.meta
                   })
C4 <-sapply(CD, 
                 function(x) {
                  x$dataset$dataset.meta$dataset.id
                   })
write.csv(C2,file="C2.csv") # The C2.csv file will be in the current working directory 
#The code above will not work if a value for altitude is null - as of Sept 16 2021 (Jerrin) 

```
Find sites where value for altitude is null
<<<<<<< HEAD
[SIMON] We need code to determine sites with missing altitude values
  [add below]
```{r Find sites where elev is null}
diat_el <- get_sites(altmin=NULL,altmax=NULL)
```
```{r  }

```
Simon - Soccorro - What is the purpose of the following code chunk?
```{r}
A1 <- c(44767,44768,44769,44770,44771,44772,44773,44774,44775,44776,44777,44778,44779,44780,44781,44782,44783,44784,44785,44786,44787,44788,44789,44790,44791)
A2<-get_datasets(A1)
A3 <-get_download(A2)
A4 <- sapply(A2, 
                 function(x) {
                   x$sample.meta$sample.id
                   })

```


(WORKING ON IT)
```{r}
s.data <- get_dataset(44764)
s.dl <- get_download(s.data)
S2 <- sapply(s.dl, 
                 function(x) {
                   x$sample.meta$sample.id
                   })
S2
S3 <-sapply(s.dl, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })
S3
```

```{R}
nla744<- read.table('VT744.txt', header=TRUE)
# This table does not currently exist in the working directory; what is it supposed to contain?  
```

(IN PROGRESS) - [Simon - this code does not work]
```{r GetSampleIDs by Dataset IDs}
NL1 <- c(49022,49023,49024,49025,49026,49027,49028,49029,49030,49031,49032,49033,49034,49035,49036,49037,49038,49039,49040,49041)
NL2 <- get_datasets(NL1) %>%
       filter(datasettype == "Diatom")
NL3 <- get_download(NL2)
NL4 <- sapply(NL3, 
                 function(x) {
                   x$sample.meta$sample.id
                   })

```

#### Dataset Type
Get dataset IDs by dataset type (Diatom, Diatom Surface Sample, Diatom Top-Bottom)

Usually, code would include criteria in addition to selecting by sample type

Example of combining data set types and using the variable to get dataset metadata from the combined object.  Example "loc = bounding box" (W,S,E,N) is northern Maine.
```{r getDiatoms, eval=FALSE} 
# Get datasets by individual diatom datatype 
neDiatoms_ss <- get_dataset(datasettype="diatom surface sample", loc= -70, 45, -68, 48)
neDiatoms_tb <- get_datasets(datasettype="diatom top-bottom", loc= -70, 45, -68, 48)
neDiatoms_dt <- get_datasets(datasettype="diatom", loc= -70, 45, -68, 48)
# Get datasets by multiple diatom datatypes 
<<<<<<< HEAD
# Combine results of search for three individual datatypes into one
neDiatoms_sstb <- c(neDiatoms_ss,neDiatoms_tb,neDiatoms_dt)
neDiatoms_sstb
#Creates an object, neDiatoms_sstb, to contain the datasets of the different diatom data types in one geographic location box [NOTE: SIMON - dataset returned is one pollen surface sample]
=======

neDiatoms_sstb <- c(neDiatoms_ss,neDiatoms_tb,neDiatoms_dt) 
#Creates an object, neDiatoms_sstb, to contain the datasets of the different diatom data types in one place
>>>>>>> c20f40bf03734e1fe6083ec5bee7604b6e43d1d1
# JERRIN / SIMON - code seems to work up to this point, but the following line does not work.

#Jerrin: The code for line 134 works but in Line 139 it is saying that it should be numerical and needs to be siteID
neDiatoms_com <- get_datasets(neDiatoms_sstb)

# neDiatoms_com includes dataset information for all three diatom data types 
```

#### Dataset type - Diatom, Diatom Surface Sample, Diatom Top Bottom

```{r getDiatomSurf, eval=FALSE}
neDiatoms <- get_datasets(datasettype="diatom surface samples", loc= BOUNDING BOX) # basic format
neDiatoms <- get_dataset(datasettype="diatom surface samples", loc= -70, 45, -68, 48) #Example
# SIMON - SOCCORRO Problem with above code - only gets data for pollen surface samples
# neDiatoms <- get_datasets(dois=c(...)) # DOI's
# SIMON - code still needs to be developed
```

Example of combining datatypes and using the variable to get dataset 

```{r getDiatomComb, eval=FALSE} 
# Get datasets by individual diatom datatype 
neDiatoms_ss <- get_datasets(datasettype="diatom surface samples", loc=BOUNDING BOX)
neDiatoms_tb <- get_datasets(datasettype="diatom top-bottom", loc=BOUNDING BOX)
neDiatoms_dt <- get_datasets(datasettype="diatom", loc=BOUNDING BOX)
# Get datasets by multiple diatom datatypes 
neDiatoms_sstb <- combine(neDiatoms_ss,neDiatoms_tb,neDiatoms_dt) 
#The combine function would take all the datasettypes to form one object
neDiatoms_com <- get_datasets(neDiatoms_sstb)

```

#### Geographic region

#####  Geopolitical units (e.g., states)

Find datasets in geopolitical units

[Simon - What is following code supposed to do?]
```{R callDatasetsbygpid}
loc <- neotoma2::get_table(x='geopoliticalunits', limit = 10000)
diat_geo <- get_dataset(gpid = X)
```

Example - get_dataset for an individual state
```{R gpidExamplePenn}
loc <- get_table(table.name='GeoPoliticalUnits')
Geo_PA <- get_dataset(gpid = "Pennsylvania")
GEO_PA1 <- get_dataset(gpid = 8412, datasettype = "diatom")
GEO_PA1b <- get_dataset(gpid = 8412, datasettype = "diatom surface sample")

# GEO_PA1c <- get_dataset(gpid = 8412, datasettype = "diatom top-bottom")# Currently function will not retrieve data for diatom top-bottom data type Sept 16 2021 (Jerrin)

Geo_PA2 <-get_download(GEO_PA1)
Geo_PA3 <-compile_downloads(Geo_PA2)
```

##### Latitude and Longitude boxes

```{R diatomsbyBBox}
# diat_LL <- get_datasets(datasettype="diatom", loc=BOUNDING BOX) - basic format
```

Example of get_datasets by location with bounding box of lat & longs (West/South/East/North)

```{R diatomsbyBBoxExecuted}
diat_NE <- get_dataset(datasettype="diatom",loc =c(-80,40,-65,48)) 
```

#### Elevation (m)
Find datasets for sites between minimum and maximum elevations

```{R getSitesByElevExample}
diat_el <- get_sites(altmin=5000,altmax=5500) #Will need to look over at a later time
diat_el
diat_el2 <- get_datasets(datasetid = diat_el)
# [Simon - code runs, but there is a problem]
```

#### Investigator name / person name
[Following code is for how to find a contact id given a contact name; still need code for how to find all datasets associated with a contact]
```{R Diatom Investigator}
Contact <- get_contact(contactname = 'X') 

```
Example of returning a contact id given the contact name
```{R Diatom Investigator name}
Don <- get_contact(contactname = 'Charles, Donald F.')
Don
# Note format of name - "last name, comma, first name, middle initial
# In addition to contactname, other possible arguments are: contactid, contactstatus, are familyname
```

#### Within or intersecting a specified time interval 
[Code still needs to be written]
```{R Diatom Time Interval,eval=FALSE}
 
```
Example
```{R}
Interval <- filter(X, age_ad >= 1950)

```

#### Taxon name or ID 
```{R getTaxa}
# Find datasets using taxon name
diat_nm<- get_dataset(taxonname = 'Navicula minima')
# Find datasets using taxon id
diat_nm1<- get_dataset(datasettype = 'diatom',taxonids = 11249)
# Find datasets of a specific data type using taxon name
# Simon - need code for finding datasets for more than one taxon at a time
diat_nm<- get_dataset(datasettype = 'diatom',taxonname = 'Navicula minima')
#To access the diatom taxa table use get_table('Taxa'), Taxon name and Taxon ID can be used to find taxa by dataset types
diat_taxa <- get_table('Taxa')

```

#### Submission date
```{r SubDate}
subdate <- get_datasets(subdate= "04-05-2016")
subdate <- get_dataset(subdate= 2016-04-04)
#Date of dataset submission, either YYYY-MM-DD or MM-DD-YYYY. 
#SIMON The above code does not work.
```

#### Dataset DOI

```{r getDiatomsByDOI}
neDiatoms <- get_datasets(dois=c(...)) # basic format
neDiatoms <- get_datasets(dois=c(43516, 43519, 46228)) # Example using DOI's for Livingston P, West P and Wolf L in the Adirondack Mountains, NY.
#JERRIN / SIMON - This code chunk does not work.  Is the DOI function still being developed?
#Jerrin's reply: I think it may have to with there being 3 dataset IDS not complying with the code and maybe that it is not ready yet. 
```

#### Collection unit type, ID or Handle [secondary]
Code to retreive datasets by collection type - usually would be one part of a larger code chunk or function

```{R diatombyColltype,eval=FALSE}
Col<- get_datasets(CollType='Core')
# SIMON/SOCORRO code doesn't work for collection units  
```

Example of getting dataset by Collection Type id
```{R sitesByCollTypeMult,eval=FALSE}
get_dataset(CollType='Core','section')
SIMON - above code does not work
```

```{R sitesByCollID,eval=FALSE}
get_dataset(CollUnitID='')
#CollUnitID Unique database record identifier for the collection unit.
#Does this code work?
```

```{R sitesByCollUnitHandle,eval=FALSE}
get_datasets(CollUnitHandle='')

#CollUnitHandle	Code name of the Collection Unit with which the dataset is associated. This code may be up to 10 characters. Data are frequently distributed by [?] Collection Unit, and the Handle is used for file names.
```
### Find datasets (multiple functions)
#### Constituent database
JERRIN / SIMON - Code needs to be added
```{R SitesbyConDB}
consDB <- get_
```

Example of finding constituent databases

```{R SitesbyConDBExample}
ConDB <- 

```

#### Sample keyword [secondary]
Code to retreive datasets by keyword - usually would be one part of a larger code chunk or function
[Code needs to be written]
```{R SitesbyKW}
get_dataset(search('x'))
```

Example of using the search function returning keywords 
```{R}
get_dataset(search('modern'))
# SIMON - Code does not work; I am not sure who wrote it
```

#### Aggregate dataset(s)
Get dataset IDs of all members of an aggregate dataset
Also, get_datasets and get-downloads
```{R Diatom Aggregate Dataset}
library(neotoma)
library(neotoma2)
aggr_set <- read.csv()# If we are going to use the Excel file that contains sampleids for each aggregate dataset, we should read it in here
<- get_datasets() # Do we need to use get_datasets if we already know sampleids?
<- get_download()
# Code needs to be written
```
Example
```{R Diatom Aggregate Dataset Example}

```

#### Publications
Get all datasetids associated with a particular publication
  Soccorro is working on this
```{R Diatom Publication}
diat_pub <- get_datasets()
```
Example - [not sure what this code does...]
```{R Diatom Publication example}
diat <- get_datasets()
diat_pub <- get_publication()
pub_diat <- sapply(diat_pub, 
                 function(x) {
                   x$pi.data$ContactID
                   })
```
#### Water chemistry
##### Is water chemistry available?
Determine if any water chemistry data is available for one or more sites or diatom datasets for those sites
If chem data are available, which parameters? (List variables included)
[SIMON - Code chunks in this section do not work]

##### From sites within range of water chemistry characteristics
Get datasets associated with water chemistry within a specific range (e.g., pH between 6 and 8)

Why is following code chunk here?
```{r getWaterChem,}
neDiatoms <- get_datasets(datasettype="diatom surface sample", loc=BOUNDING BOX)
```

Example of how to get water chemistry from the different dataset types [includes snippets of code, none of which work]

```{r getWaterChemEX}
diatomss <- get_datasets(datasettype = 'diatom surface sample') %>% 
  get_downloads()

waterchem <- get_datasets(datasettype = 'water chemistry') %>% 
  get_downloads() %>% 
  filter(pH < 5)

diatomss <- get_aggregate(123)
waterss <- get_aggregate(124)

diatomdl <- get_downloads(diatomss) %>% compile_downloads()
waterdl <- get_downloads(waterss) %>% compile_downloads()

# This would take two sets of sites, datasets or downloads and
# order them in the right order.
aligned <- align_sites(diatomss, waterss)
```

```{r fixing}
diatomss<- get_dataset(datasettype = 'diatom surface sample')
waterss<- get_dataset(datasettype = 'water chemistry')
diatom<- get_dataset(datasettype = 'diatom')
#Sapplyy function is used to return diatomss, read / extract the metadata and select dataset IDs for the first 20 lakes 
subsetss <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]
#Sapplyy function is used to return diatom, read / extract the metadata and select dataset IDs for the first 20 lakes 
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') # It returns the file that is used 
} else {
  diat_dl <- get_download(subset)
  diat_dlss <- get_download(subsetss)
  diat_dl <- bind(diat_dl, diat_dlss)
  saveRDS(diat_dl, 'filename') # It saves this as an object of the download with file
#  Where is "filename"saved? - What directory? - type getwd() in the console to find out where the file is.
}
```



##### From sites where one or more specified water chemistry characteristics were measured
```{R Diatom Multiple Water Chemistry}
# [SIMON - SOCCORRO - The code below works, but retreives data for different sets of lakes.  Water chemistry for one set of 20 lakes and diatom data for a different set of 20 lakes.  We need code that will get count data and water chemistry data for the same lakes.  May require reading a file that has lists of corresponding diatom and water chemistry sample ids]
diatomwch<- get_dataset(datasettype = 'water chemistry')
diatom<- get_dataset(datasettype = 'diatom surface sample')

subsetwch <- sapply(diatomwch, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('fileWCH' %in% list.files()) {
  diat_dl <- readRDS('fileWCH') # It returns the file that is used 
} else 
  diat_wch <- get_download(subsetwch)
  diat_dls <- get_download(subset)
  diat_dlb <- bind(diat_wch, diat_dls)
  saveRDS(diat_dlb, 'fileWCH')
  # fileWCH will be created in the working directory
  wideWCH_DTM <- compile_downloads(diat_dlb) 
## neotoma function converts multiple downloads into single object 
minWCH <- wideWCH %>% 
  group_by(dataset) %>% #dataset was returned from the table 
  summarise(min(depth)) #dplyr function to create a dataframe
  
wideWCH_DTM %>% filter(is.na(depth))
# Write data to an Excel file, which will be created in the working directory
WriteXLS(wideWCH_DTM, "wideWCH_DTM.xlsx")
```



#### Diatom Sample analyst name
Get all datasets associated with name of a sample analyst
[SIMON - Currently seems to just get a list of people who analyzed surface samples
Needs to be able to accept contact ID of a specific person
```{R Diatom Sample Analyst}
Con_<- get_dataset
Contact_diat <- get_dataset(datasettype = 'diatom')

Analyst <- sapply(Contact_diat, 
                 function(x) {
                   x$pi.data
                   })
```
Example
[Simon - Can this code be modified so it retrieves all dataset IDs associated with an specific example person?]
```{R Diatom Sample Analyst example}
Con_<- get_dataset(32252)
Contact_diat <- get_dataset(datasettype = 'diatom')
Con_U <- sapply(Con_, 
                 function(x) {
                   x$pi.data
                   })
```


#### Diatom taxa
##### Diatom counts include one or more specific diatom taxa
[SIMON - Code does not include possibility of specifying a particular diatom taxon

Get list of taxa found in a single dataset (core)

```{R datasetByTaxa}
diat_tax <- get_dataset(32252) # Datasetid for U Wallface P core 1
diat_dl <- get_download(diat_tax)
diat_d2 <- compile_downloads(diat_dl)
diat_taxa <- taxa(diat_dl)
```

Get list of all taxa associated with single datasettype 

```{R datasetByTaxaExample}
diatoms<- get_dataset(datasettype = 'diatom')
diat_dl <- get_download(diatoms)
diat_taxa <- taxa(diat_dl) # List of taxa in all datasets of dataset type "diatom"
```


##### Diatom counts include only taxa with abundance greater than x percent (in sample or core)

```{R Diatom Counts}

```

Example

```{R Diatom Counts EX}

```

#### Site characteristics
##### Site area larger or smaller than specified size

```{R Diatom Site Area}

```

Example

```{R Diatom Site Area EX}

```

#### Depository in which diatom slides are located

```{R Depository}
diat.data <- get_dataset(datasettype='diatom') # access to neotoma explorer but needs to specify 
browse(diat.data)
```

Example
```{R Depository EX}
library(neotoma)
```
#### Chronology
Does a dataset have an associated chronology?  If so, what are metadata (e.g., upper and lower age bounds)?
  Not sure of purpose of the following code
```{R Chron }
get_chroncontrol('x')# Can be thought like how bacon model is run through R
```
Example
```{R AnotherChronExample}

```
##### Chronology (y/n) and characteristics
```{R Chronology}
<-get_chroncontrol(x) # Need to check if this relates to chronology or bacon 
```

Example
```{R ChronologyExample}

```


### Format for browsing using multiple criteria - Examples 
Examples: [could get complicated]  General rules and tips.  [Add as they become known]
### [Following sections to be reorganized]
#### Find all diatom datasets of any datatype

#### Find all diatom datasets of any datatype within a geographic region

#### Find all diatom surface sample datasets within a geographic region

#### Find datasets .... with surface area larger than x ha .......

### Other options / Misc:




### Create output of browse results 
Minimum “list” of dataset, collection, and / analysis unit ids for further browsing and use as input to other R functions. 
 
Standard comprehensive output file for use in detailed browsing. Variables should include all of the following (variables are grouped by their location on Tilia tabs): 
  1.  Site information: Site ID, Site name, Latitude, Longitude, Latitude width, Longitude width, Country, State, County, Admin Unit (3rd Geographic Unit), Lake characteristics, publication id
  2. Collection unit information:  CU ID, Type, Collection unit name, Collection unit handle, Location in site, Collection device, Date collected, Water depth of collection
  3.  Dataset information: Data Type (Diatom, Diatom surface sample, or Diatom top-bottom), Primary publication, Investigators [or first author of publication], Sample analyst


## Create output files for data analysis

The create data output files section -  standard formats for diatom counts, metadata, chronology, water chemistry.  It provides examples for retrieving data and creating output files in a few basic formats.  Formats include those that can be used as input to data analysis programs - R packages and others.  In general, they should include all related data; the amount of data can be reduced later.They will include several descriptive variables and be easily readable. [input to code chunks can include output from browse tasks]

### Basic files / matrices

#### Diatom counts
- single sites and multiple sites; aggregate data set; stratigraphic vs surface sample vs top-bottom; percentages vs raw counts.

##### Create a count data file for a single site
JERRIN / SIMON - code does not run - "Error in get_dataset.default(schrader) : siteid must be numeric."
```{r get_singleSitebyName}
schrader <- get_sites(sitename = 'Schrader Pond') # % can be used to approximate sitenames
schrader.data <- get_datasets(schrader)
schrader.dl <- get_download(schrader.data)
schrader.cnt <- counts(schrader.dl)
sapply(schrader.cnt, dim) 
print(schrader.dl)
```

EXAMPLE TESTING OF FILTERING 
```{R UpperWallfaceEXAMPLE}
uwallface <-get_site('Upper Wallface%') 
uwall <- get_dataset(32252) # diatom datasetid for UWall is 32252
uwallface.dl <- get_download(uwall)
## Sapplyy function is used to return diatomss and with the function it is reading the metadata and selectind dataset,id to query from first 20 lakes 
#### JERRIN Review this example with me
subsetUWall <- sapply(uwall, 
                   function(x) {
                     x$dataset.meta$dataset.id
                   })

if('UWall' %in% list.files()) {
  UWa_dl <- readRDS('UWall') # It returns the file that is used 
} else {
  UWallf_dl <- get_download(subsetUWall)
  saveRDS(UWallf_dl, 'UWall') # It saves this as an object of the download with file
}

wideCounts <- compile_downloads(UWallf_dl) 
## neotoma function converts multiple downloads into single object 
minRow <- wideCounts %>% 
  group_by(dataset) %>% #dataset was returned from the table 
  summarise(min(depth)) #dplyr function to create a dataframe
  
wideCounts %>% filter(!is.na(Eunotia.diodon))
## dplyr function used to subset a data frame
diat_taxa <- taxa(UWallf_dl)
```
[Simon - Just wondering why full taxa names are pulled from the database instead of, or in addition to, taxa codes - Joy]  

Upper Wallface Pond examples
```{R Upper Wallface EX}
library (neotoma)
### Find Neotoma Site Id for Upper Wallface Pond 
uwallface <- get_site (sitename = "Upper Wallface%")
### Find datasets and IDs associated with U Wallface Pond
uwallface.dl<- get_dataset(uwallface)  # Review datasets available note ID of the one of interest
### download data for diatom core dataset (Dataset 32252)
uwallface.dw <- get_download (32252)
### Get diatom counts for dataset 32252
uwallface.ct <- counts (uwallface.dw)
### Find the number of intervals and number of taxa in a count
sapply(uwallface.ct, dim)
### Look at the matrix of diatom counts
glimpse (uwallface.ct)
str(uwallface.dw) # str is a useful function to see the overall data structure for a dataset 
Comp_UWall <- compile_downloads(uwallface.dw) # used for formatting into a table 
write_xlsx(uwallface.ct,  ".xlsx")

```

```{R Upper Wallface View counts}
### View sample metadata, list of taxa, and counts in Download dataframes 
### View sample metadata,
uwallface.dw[["32252"]][["sample.meta"]] 
### View taxa list
uwallface.dw[["32252"]][["taxon.list"]]
### View diatom counts
uwallface.dw[["32252"]][["counts"]]
### View Chronology
uwallface.dw[["32252"]][["chronologies"]]
```

##### Get count data for a diatom surface sample
Get data from from all datasets of "diatom" and diatom surface sample dataset types
Example of getting surface sample through filtering and usng multiple data set types to get metadata
Note: similar code for getting output of water chmistry data is below, around line 350
```{R datasetByTaxa with DBT}
## Simon Edited this:
diatomss<- get_dataset(datasettype = 'diatom surface sample')
diatom<- get_dataset(datasettype = 'diatom')
#SIMON - "diatom top-bottom" needs to be added as a choice for datasettype.
#Sapplyy function is used to return diatomss and with the function it is reading the metadata and selecting dataset,id to query from first 20 lakes 
subsetss <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id 
                   })[1:20]
#In the subsets it would go through each dataset to match the search of the metadata location 
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') # It returns the file that is used 
} else {
  diat_dl <- get_download(subset)
  diat_dlss <- get_download(subsetss)
  diat_dl <- setdiff(diat_dl, diat_dlss)
  saveRDS(diat_dl, 'filename') # It saves this as an object of the download with file
}

wideCounts <- compile_downloads(diat_dl) 
#neotoma function converts multiple downloads into a single object 
minRow <- wideCounts %>% 
  group_by(dataset) %>% #dataset was returned from the table 
  summarise(min(depth)) #dplyr function to create a dataframe 
#Overall count data is retrieved from this portion 
wideCounts %>% filter(!is.na(Cornus)) # SIMON this line does not work 
#dplyr function used to subset a data frame
diat_taxa <- taxa(diat_dl)# The function taxa returns a data frame of taxa for an (object)
```

 

Example of using get_dataset to get diatom top-bottom samples (currently not usable since Top-Bottom not in package)
```{R datasetByTB,eval=FALSE}
library(neotoma)
diatomss<- get_dataset(datasettype = 'diatom top-bottom') # top-bottom not a dataset yet
diatom<- get_dataset(datasettype = 'diatom')
#Sapplyy function is used to return diatomss and with the function it is reading the metadata and select in dataset,id to query from first 20 lakes 
subsettb <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id # Location of the data
                   })[1:20]
#In the subsets it would go through each dataset to match the search of the metadata location
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') 
} else {
  diat_dl <- get_download(subset)
  diat_dltb <- get_download(subsettb)
  diat_dl <- bind(diat_dl, diat_dltb)
  saveRDS(diat_dl, 'filename')
}
#It would return results of the top-bottom to bind them and present in a table format 
```


#### List of diatom taxa
[Simon - following code does not work - (Error: object 'x' not found)
Create file of all diatom taxa in the Neotoma master list - with name, authority, code, notes, etc.
```{R, diatom taxa out}
x
Taxa_hi <- sapply(x, 
                 function(x) {
                   x$taxa
                   })
compile_taxa
```
Example of returning taxa [Not sure what this code is supposed to do = DFC]
(IN PROGRESS)
```{R ListTaxaExample}
get_dataset(taxonids = )
get_dataset(datasettype = 'Diatom',taxonname = 'x')
```

```{R Upper Wallface EX}
library (neotoma)
### Find Neotoma Site Id for Upper Wallface Pond 
uwallface <- get_site (sitename = "Upper Wallface%")
### Find datasets and IDs associated with U Wallface Pond
uwallface.dl<- get_dataset(uwallface)  # Review datasets available note ID of the one of interest
### download data for diatom core dataset (Dataset 32252)
uwallface.dw <- get_download (32252)
### Get diatom counts for dataset 32252
uwallface.ct <- counts (uwallface.dw)
### Find the number of intervals and number of taxa in a count
sapply(uwallface.ct, dim)
### Look at the matrix of diatom counts
glimpse (uwallface.ct)
str(uwallface.dw) # str is a useful function to see the overall data structure for a dataset 
Comp_UWall <- compile_downloads(uwallface.dw) # used for formatting into a table 
WriteXLS(uwallface.ct,  "count_file.xlsx")

```
### Site information and environ data

#### Water chemistry
```{R WCHM Out}
get_dataset(sitename='x',datasettype = 'diatom')
```
Example
```{R ChemistryExample}

```
#### Chronology


#### Metadata - various options
```{R Metadata}
get_download()# Options within diatoms to organize it 
get_dataset()
```
Example
```{R DownloadStuffExample}
get_download()
get_dataset()
```

#### Other types of data 
- LOI, geochemistry
```{R ETC}
get_dataset(datasettype="")
```
Example
```{R ETC EX}
get_dataset(siteid=,)
```


Issues:  Put metadata in the same files as the data matrices?  How to combine related files (e.g., diatom counts and chronology)? [When is it best to convert diatom counts to percentages?]

### Input files for data analysis programs
  Some programs have no standard input format
#### Bacon, ### Vegan, ### Rioja, ### Tidypaleo
#### Others 

## Make plots and maps 
(e.g., stratigraphic diagrams, maps of taxa distributions)

```{r plot}
library(leaflet)
test <- c(44764, 44765, 44766)
all_wi <- neotoma::get_dataset(test, datasettype = "diatom")
# We're going to use this multiple times I think, so let's make it a function:
leaflet_map <- function(dataset_in) {
  dataset_summary <- do.call(rbind, lapply(dataset_in, 
                        function(x){
                          # here we pull out the site information from the `dataset` objects:
                          data.frame(name = x$site.data$site.name,
                                     lat  = x$site.data$lat + runif(1, -0.005, 0.005),
                                     long = x$site.data$long + runif(1, -0.005, 0.005),
                                     type = x$dataset.meta$dataset.type)
                        }))
  # The leaflet package documentation uses piping.  For the sake of this tutorial, I won't.
  # First, define a color palette for the dataset type symbol plotting.
  pal <- colorFactor("Dark2", domain = levels(dataset_summary$type))
  # Now make the leaflet map, add base raster tiles and then add the markers for the records:
  map <- leaflet(data = dataset_summary)
  map <- leaflet::addTiles(map)
  map <- leaflet::addCircleMarkers(map, ~long, ~lat, 
                                   popup = ~paste0("Site: ", as.character(name), "<br>",
                                                   "Type: ", 
                                                   as.character(dataset_summary$type)),
                                   color = ~pal(type),
                                   stroke = FALSE, fillOpacity = 0.5)
  # You need to explicitly call the `map` object to make it appear!
  map
}
# Since that's all wrapped in a function, we can all it with any `dataset_list`:
leaflet_map(all_wi)
```



### Plot of the abundance of multiple diatom taxa 
for a single core - vs depth or time
### Plot of abundance of a single taxon 
for cores from multiple sites - vs time
### Plot of abundance of a taxon vs an environmental characteristic 
(e.g., water chemistry variable)
### Map of distribution of sites 
For example, that are part of an aggregate dataset; GGPlot, Leaflet

### Map of distribution of a diatom taxon
; symbol size related to % abundance

## Modify and analyze data 
- and other miscellaneous tasks
### Add to or modify data in Neotoma

### Add aggregate datasets to Neotoma

### Create new ecological groups and assign taxa to the groups
```{R set taxa}
set_taxa('x') # Not code but could be something

Example
```{R set taxa ex}

```

### Add to a table that explicitly matches water chemistry and diatom datasets
This is especially important for cases where sites were sampled for water chemistry as part of more than one study.

### Extract a list of publications for a set of datasets
```{R get pub out}
<- get_publications(datasetid= x)
### JERRIN - review following example with me
### So it would involve contact name/ID, publication ID, datasets having publication  
```

### Extract a list of DOI’s for a set of datasets
```{R DOIS}
get_publications(datasetid=)# Not code seems to need to be a mix of get_dataset and get_publications
```
Example
```{R DOIS EX}

```

### Add standard sets of diatom taxa names that could be used to convert multiple synonyms to another set of names
```{R standard set}
get_dataset(taxonname = ,search())
```

## Create Output files
The following items will be moved to corresponding topics in the outline above
### Diatom counts
SIMON ASSISTED EXAMPLE [Example provided by Simon Goring - date]
Creates file with diatom counts for surface samples 
```{R datasetByTaxa from Simon}
library(dplyr)
library(purrr)
# Get diatom datasets (Diatom and Diatom Surface Sample data types) for all sites in the northeast US, defined as a set of states.
gpids <- c(8412, 7990, 7934, 7326, 7923, 8981, 6442, 7368)

ne_diatom <- map(gpids, function(x)
  neotoma:::get_dataset(gpid = x,datasettype="diatom")) %>%
  neotoma::bind()   
  
ne_diatomSS <- map(gpids, function(x)
  neotoma:::get_dataset(gpid = x,datasettype="diatom surface sample"))%>% 
  neotoma::bind() 
ne_dataset<-bind(ne_diatom,ne_diatomSS)


if('DiatomFil' %in% list.files()) {
  Diatom_dl <- readRDS('DiatomFil') 
} else {

  allDatasets <- list()
  
  for(i in length(allDatasets):length(ne_dataset)) {
    allDatasets[[i]] <- get_download(ne_dataset[[i]])
  }
  
  ne_download <- neotoma::bind(allDatasets)
  
  saveRDS(ne_download, 'DiatomFil')
}

# Create diatom count files
wideCounts <- compile_downloads(Diatom_dl) 
minRow <- wideCounts %>% 
  group_by(dataset) %>% 
  summarise(min(depth)) 
```

Jerrin Example of using just dataset ID
### Example similar to above but starting with a set of dataset ID's
```{R ExampleDataset}
library(purrr)
V1 <-c(44786,44787,44788)
#In this example we take these 3 sites with combine function 
V1_diatom <- map(V1, function(x)
  neotoma:::get_dataset(x,datasettype="diatom")) %>%
  neotoma::bind()   
#In the get_dataset line, whatever is in the parenthesis is a parameter such as x or gpid in which it will take from V1 since it was stated in the line above it

if('V1' %in% list.files()) {
  V1_dl <- readRDS('V1') 
} else {

  V1Datasets <- list()
  #
  for(i in 1:length(V1_diatom)) {
    V1Datasets[[i]] <- get_download(V1_diatom[[i]])
  }
  #For loop will being going through each step to first create the file and go through each site with the download
  V1_download <- neotoma::bind(V1Datasets)
  
  saveRDS(V1_download, 'V1')
}
V1Counts <- compile_downloads(V1_download) 
V1Row <- V1Counts %>% 
  group_by(dataset) %>% 
  summarise(min(depth))
write_xlsx(V1Counts,  ".xlsx")

#This last step is the way to create a table which can be written as csv to export out 

```

Example of getting information for a single site ID using get_dataset with subsets to return counts.  Created by Simon Goring
add comments
```{R ExampleSingleSite }
Mirror<- get_dataset(39813) # Dataset ID for Mirror Lake, Newer dataset/ site ids does not seem to work 
subsetda <- sapply(Mirror, 
                 function(x) {
                   x$dataset.meta$dataset.id 
                   })
# The subset is not a function but a way to filter the dataset to get the portions of interest and sapply is from R package  
if('Mirror' %in% list.files()) {
  diat_da <- readRDS('Mirror') 
} else {
  diat_dla <- get_download(subsetda)
  saveRDS(diat_dla, 'Mirror')
}
#In the if and else loops they work together that a file will be created and download the data from the subset
diatCount <- compile_downloads(diat_da) 
minimumRow <- diatCount %>% 
  group_by(dataset) %>% 
   summarise(min(depth))
#In compiling downloads it displays the information in a table format and could be organized with group_by and summarise function
```





