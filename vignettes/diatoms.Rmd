---
title: "Working with diatom data in the neotoma2 R package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Working with diatom data in the neotoma2 R package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup}
library(neotoma2)
library(neotoma)
```

Some code in this document was borrowed from the Neotoma2 markdown document prepared by Simon Goring and Socorro Dominguez and the original Neotoma R package. 

One of the main goals of Neotoma R is to pull records out of the Neotoma database and into the R workflow.  

# Introduction

The ultimate purpose of this document is to provide general guidance and specific code examples for those wanting to use Neotoma R2 to retrieve and work with Neotoma diatom data.  An initial purpose is to help programmers (Simon, Socorro) develop Neotoma2 resources by providing a structured description of how diatom researchers may wish to use N-R2, and specific tasks they may wish to accomplish.  

Because N-R2 was being developed during the time this vignette documentation was being prepared, not all the original package functions were available in N-R2.  Therefore functions from both packages are used.  Over time, original package functions should be replaced with corresponding N-R2 functions. In the code chunks below, "neotoma::" is used to refer to functions in the original neotoma R package, for example, "neotoma::"get_site(whatever)"

This document is organized to address two main goals of users, to browse the database to identify datasets that meet specified criteria, and to create output files that can be used for further analysis.  Other goals are to create plots and maps and to analyze data using R code.


# Browse data

The browse section describes ways of searching for available diatom datasets using a variety of criteria, either alone or in combination.  Criteria include those available in Neotoma Explorer, plus several more. Examples also include options for viewing and saving output results.

## Find diatom datasets using search criteria

General task specification format: “Find all diatom datasets that meet the following criteria.”  [Chunks below show generic code specifying how to search / filter by a single criterion, followed by an example] 

General format of a complete chunk to browse using a single criterion:

```{R genericGetDataset}
diat_1 <- get_datasets(argument_1, argument_2)

```

Example for getting Datasets by specifying dataset type and bounding box location

```{R retrieveDiatoms}
NE_US_DTM<-get_dataset(datasettype='diatom', loc =c(-80,40,-65,48))
#This example code gets dataset metadata for datasettype "diatom" from sites within a latitude and longitude bounding box
```
### Site Name
Get site data for a single site using sitename
Note:  get_site is a Neotoma_R function.  It returns 6 location variables for each site; get_sites is a Neotoma2_R function that also retreives location information, and associated collection units and datasets as well.
```{r sitesbyName example}
diat_1 <-get_sites(sitename = "Name of site")  # Basic format
diat_2 <-get_sites(sitename= 'Schrader Pond')  # Example
diat_2.5 <-get_sites(sitename= '%Schra%')      # Example using wildcards (%)
diat_2
```
Get data on multiple sites using site names
```{r multsitesbySitename example}
library(neotoma)
# The get_site function (Neotoma R) can process only one lake at a time.  The code chunk here retrieves data for multiple lakes.  It was created by Soccorro Dominguez.  The get_sites function being developed in Neotoma2 may allow processing of multiple sites.
# Create an object that contains names of lakes in quotations and separated by commas.  A new object must be created for each new set of names.
Names_744BH<-c("Bald Hill", "Blake (sutton)", "High (sudbry)", "Holland", "Little Hosmer", "Long (grnsbo)", "Long (shefld)", "Round (shefld)")  #Example set of lake names
# Create object "new_sites".
new_sites <- c() 
# Run a loop that gets sites for each name in the object containing lake names
for(name in Names_744BH){
sites <- get_sites(sitename = name)
new_sites <- c(new_sites, sites)}
#Sites would create a new object from the the loop of all the lakes
# JERRIN / SIMON - Code above does not work.  "Error in check_args(...) : Sitename should be a character"  Please try to fix.
```

Getting multiple sitenames and NLA Example to get siteIDS
```{r NLA}
library(neotoma)
library(neotoma2)

nlaxl <- c("Gardner Pond","George Wyth Lake","Goose Pond","Gorton Pond","Grassy Pond","Green Belt Lake","Grimes","Grist Millpond","Grittman Lake","Groton Reservoir","Half Moon Lake","Halfway Pond","Hannaberry Lake","Harper Lake","Haskell Lake","Heggs","Henry's Lake","Hert Lake","Highland Lake","Hi-Land Lake","Hinkley's Pond","Horsfall Lake","Hosmer Lake")
nla_sites <- c() 
# Run a loop that gets sites for each name in the object containing lake names
for(name in nlaxl){
sites <- get_sites(sitename = name)
nla_sites <- c(nla_sites, sites)}
```

### Site ID
Get data on a single site by using siteid
```{r sitesbySiteID example}
diat_3<-get_sites(siteid= x)
diat_4<-get_sites(siteid= 27408) # Example for single site 
#The get_site function will return basic metadata: sitename,location and collection unit 
```

Get data on multiple sites by using siteids 
```{r multsitesbySiteIDs example}
#Create an object to contain multiple Site IDs to be used as argument for get_sites function
diat_5 <- c(25918,25919,25920) #Site IDs for Jackson P., Jellison Hill P., and Jimmie P.
diat_6 <- get_sites(diat_5)
# JERRIN / SIMON - this code does not work.  "Error: C stack usage  7970768 is too close to the limit".  Please try to fix. 

#Jerrin: The code should work and would return 3 sites and 6 parameters. It may have to with the difference of Windows and Mac OS. 

```

```{r NLA multiple siteID}
nlad<-c(8556,8556,10427,13527,23249,23250,23251,24214,23252,23253,23254,23255,23256,23259,23260,23261,23262,23263,23264,23265,9734,23272,23273,23274,9596,26597,23275,23276,23277,23278,23279,2625,9602,23280,23281,23282,23283,10113,10114,13393,10113,10114,13393,24385,23284,23287,23288,23289,23290,23296,23297,23298,23299,23300,23301,23302,23303,23305,23306,23307,23308,23309,9658,16646,23310,8566,9870,23311,23314,23315,23316,23317,23318,23319,23321,23322,27324,23323,23324,9903,23325,481,14085,22469,22812,23327,23328,500,502,7532,9667,23329,26516,23330,23331,24304,23332,2709,9927,10429,23333,2709,9927,10429,23333,23334,9929,23336,23343,23344,23345,23347,23348,23350,23351,23352,23353,23354,2688,9972,13354,23355,27622,762,9980,23357,27642,23358,23360,9679,23361,23362,23363,23364,23365,23366,23367,23368,23369,23370,23372,23373,10266,23374,23375,23376,22863,23377,23378,23379,23381,23382,23383,23384,23385,24387,24273,24390,24391,24392,2686,24394,24395,24397,24398,24399,24401,24402,24403,22900,24404,24405,24406,24408,24409)
nla_1<-get_sites(nlad)
nla_2<-get_datasets(datasettype="diatom surface samples",nlad)
# An example showing how to get multiple datasets of data type "diatom surface sample" using a set of site IDs.  
#This code will not run if the value for the "altitude" variable is blank for any one lake. Soccorro is trying to fix this problem.
```
### Dataset ID
Get data on a single dataset using datasetID 
```{r get datasetID}
diat_ID <- get_dataset(datasetid)
diat_ID <- get_dataset(44764) # Example
#get_dataset could use site id or dataset id  to return information on site, metadata, publication, and date submitted 
```
Get datasets using multiple dataset ids 
```{r multdatsetid }
multid <- c(44764,44765,44766)
diat_multid <- get_dataset(multid) # Example
#Multiple dataset ids combined to put in a object will run get_dataset so less code needs to be created 
```

### Dataset DOI

```{r getDiatomsDSType}
neDiatoms <- get_datasets(dois=c(...)) # basic format
neDiatoms <- get_datasets(dois=c(43516, 43519, 46228)) # Example using DOI's for Livingston P, West P and Wolf L in the Adirondack Mountains, NY.
#JERRIN / SIMON - This code chunk does not work.  Is the DOI function still being developed?
#Jerrin: I think it may have to with there being 3 dataset IDS not complying with the code and maybe that it is not ready yet. 
```

### Dataset Type
 Diatom, Diatom Surface Sample, Diatom Top-Bottom
Example of combining data set types and using the variable to get dataset metadata from the combined object.  Example "loc = bounding box" (W,S,E,N) is northern Maine.
```{r getDiatoms, eval=FALSE} 
# Get datasets by individual diatom datatype 
neDiatoms_ss <- get_datasets(datasettype="diatom surface samples", loc= -70, 48, -68, 48)
neDiatoms_tb <- get_datasets(datasettype="diatom top-bottom", loc= -70, 48, -68, 48)
neDiatoms_dt <- get_datasets(datasettype="diatom", loc= -70, 48, -68, 48)
# Get datasets by multiple diatom datatypes 

neDiatoms_sstb <- c(neDiatoms_ss,neDiatoms_tb,neDiatoms_dt) 
#Returns the [Creates an?] object neDiatoms_sstb to contain the datasets of the different diatom data types in one place
# JERRIN / SIMON - code seems to work up to this point, but the following line does not work.

#Jerrin: The code for line 134 works but in Line 139 it is saying that it should be numerical and need to be siteID
neDiatoms_com <- get_datasets(neDiatoms_sstb)
# neDiatoms_com includes dataset information for all three diatom data types 
```


### Geographic region
Using get_site to return a location in geopolitical table with gpid
```{r get site by gpid}
diat_1<-get_site(gpid = x)
diat_1<-get_site(gpid = 6198) # Geopolitical ID for Alaska from Table
#The gpid is found from the GeoPoliticalUnits table 
```

The geopolitical table to search for locations 
```{r getGeoPolUnits}
gpids <- neotoma::get_table(table.name='GeoPoliticalUnits')
#gpid is useful to find country and state boundaries 
```

Example - get sites from multiple geopolitical units (e.g., states)
```{r retrieveByGeopol}
library(dplyr)
library(purrr)

gpids <- c(8412, 7990, 7934, 7326, 7923, 8981, 6442, 7368)
ne_sites <- map(gpids, function(x)
  neotoma:::get_site(gpid = x)) %>%
  neotoma::bind()
ne_down <- neotoma::get_download(ne_sites)
#The code will run each gpid with the get_site that will be binded and than downloaded to display the data 
```

####  Geopolitical units (e.g., states)
```{R callDatasetsbygpid}
loc <- neotoma2::get_table(x='geopoliticalunits', limit = 10000)
diat_geo <- get_dataset(gpid = X)
```

Example - get_dataset for an individual state
```{R gpidExamplePenn}
loc <- get_table(table.name='GeoPoliticalUnits')
Geo_PA <- get_dataset(gpid = "Pennsylvania")
GEO_PA1 <- get_dataset(gpid = 8412 )
```

#### Latitude and Longitude boxes

```{R diatomsbyBBox}
diat_LL <- get_datasets(datasettype="diatom", loc=BOUNDING BOX)
```

Example of get_datasets by location with bounding box of lat & longs (West/South/East/North)

```{R diatomsbyBBoxExecuted}
diat_NE <- get_datasets(datasettype="diatom",loc =c(-80,40,-65,48)) 
```

#### Elevation (m)

```{R sitesbyElev,eval=FALSE}
diat_el <- get_sites(`altmin()`, `altmax()`)
```
Example of getting datasets for sites between minimum and maximum elevations 
```{R getSitesByElevExample}
diat_el <- get_sites("altmin(5000)","altmax(5500)") #Will need to look over at a later time 
diat_el2 <- get_datasets(datasetid= diat_el)
```






### Collection type [secondary]
```{R diatombyColltype,eval=FALSE}
get_dataset(CollType='x') # Unsure
```
Example of getting dataset by collection id
```{R sitesByCollTypeMult}
get_dataset(CollType='Core','Section')
```

### Constituent database
JERRIN / SIMON - Code needs to be added
```{R SitesbyConDB}
#Getting constituent databases would need to be in metadata but not sure if it is 
```

Example of finding constituent databases

```{R SitesbyConDBExample}
ConDB <- 
```

### Sample keyword [secondary]
```{R SitesbyKW}
get_dataset(search('x'))
```

Example of using the search function returning keywords 
```{R}
get_dataset(search('modern'))# Search could find so maybe
```

### Within or intersecting a specified time interval 
```{R Diatom Time Interval,eval=FALSE}
 

```
Example
```{R}
Interval <- filter(X, age_ad >= 1950)

```

### Member of aggregate dataset(s)
```{R Diatom Aggregate Dataset}
library(neotoma)
library(neotoma2)
aggr_set <- read.csv()# If we are going to use the excel file we should read it here and than could use it to find information
<- get_datasets()
<- get_download()
#General guideline steps when we do get info to use for other purposes 


```
Example
```{R Diatom Aggregate Dataset Example}

```

### Related to one or more publications
Get all dataset IDs associated with a particular publication
```{R Diatom Publication}
diat_pub <- get_datasets()
```
Example - [not sure what this code does...]
```{R Diatom Publication example}
diat <- get_datasets()
diat_pub <- get_publication()
pub_diat <- sapply(diat_pub, 
                 function(x) {
                   x$pi.data$ContactID
                   })
```
### Water chemistry
#### Is water chemistry available? 
(List variables included) 
#### From sites within range of water chemistry characteristics
```{r getWaterChem,}
neDiatoms <- get_datasets(datasettype="diatom surface samples", loc=BOUNDING BOX)
```
Example of how to get water chemistry from the different dataset types
```{r getWaterChemEX}
diatomss<- get_dataset(datasettype = 'diatom surface sample')
diatom<- get_dataset(datasettype = 'diatom')
#Sapplyy function is used to return diatomss and with the function it is reading the metadata and selectind dataset,id to query from first 20 lakes 
subsetss <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]
#The $ is extracting the surface sample metadata from the name of it 
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') # It returns the file that is used 
} else {
  diat_dl <- get_download(subset)
  diat_dlss <- get_download(subsetss)
  diat_dl <- bind(diat_dl, diat_dlss)
  saveRDS(diat_dl, 'filename') # It saves this as an object of the download with file
}
```



#### From sites where one or more specified water chemistry characteristics were measured
```{R Diatom Multiple Water Chemistry}
WCH_Sites <-c()

diatomss<- get_dataset(datasettype = 'diatom surface sample')
diatom<- get_dataset(datasettype = 'diatom')

subsetss <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })

subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') 
} else {

  saveRDS(diat_dl, 'filename') 
}
WCH_Diat <- compile_downloads(diat_dl)
```


### Diatom Sample analyst name
```{R Diatom Sample Analyst}
Con_<- get_dataset
Contact_diat <- get_dataset(datasettype = 'diatom')

Analyst <- sapply(Contact_diat, 
                 function(x) {
                   x$pi.data$
                   })
```
Example
```{R Diatom Sample Analyst example}

```

### Investigator name / person name
```{R Diatom Investigator}
Contact <- get_contact(contactname = 'X')

```
Example of returning a contact id given the contact name
```{R Diatom Investigator name}
Don <- get_contact(contactname = 'Donald F. Charles')
```
### Diatom taxa
#### Diatom counts include one or more specified diatom taxa

```{R datasetByTaxa}
diatoms<- get_dataset(datasettype = 'diatoms')
diat_dl <- get_download(diatoms)
diat_taxa <- taxa(diat.dl)
```

Example of getting  the downloads of a datasettype 

```{R datasetByTaxaExample}
diatoms<- get_dataset(datasettype = 'diatoms')
diat_dl <- get_download(diatoms)
diat_taxa <- taxa(diat.dl)
```

#### Diatom counts include only taxa with abundance greater than x percent (in sample or core)

```{R Diatom Counts}

```

Example

```{R Diatom Counts EX}

```

### Site characteristics
#### Site area larger or smaller than specified size

```{R Diatom Site Area}

```

Example

```{R Diatom Site Area EX}

```

### Depository in which diatom slides are located

```{R Depository}
diat.data <- get_dataset(datasettype='diatom') # access to neotoma explorer but needs to specify 
browse(diat.data)
```

Example
```{R Depository EX}
library(neotoma)
```
### Chronology
Does a dataset have an associated chronology?  If so, what are metadata (e.g., upper and lower age bounds)?
  Not sure of purpose of the following code
```{R Chron }
get_chroncontrol('x')# Can be thought like how bacon model is run through R
```
Example
```{R AnotherChronExample}

```
#### Chronology (y/n) and characteristics
```{R Chronology}
<-get_chroncontrol(x) # Need to check if this relates to chronology or bacon 
```

Example
```{R ChronologyExample}

```


### Format for browsing using multiple criteria - Examples 
Examples: [could get complicated]  General rules and tips.  [Add as they become known]

#### Find all diatom datasets of any datatype

#### Find all diatom datasets of any datatype within a geographic region

#### Find all diatom surface sample datasets within a geographic region

#### Find datasets .... with surface area larger than x ha .......

### Other options / Misc:




## Create output of browse results 
Minimum “list” of dataset, collection, and / analysis unit ids for further browsing and use as input to other R functions. 
 
Standard comprehensive output file for use in detailed browsing. Variables should include all of the following (variables are grouped by their location on Tilia tabs): 
  1.  Site information: Site ID, Site name, Latitude, Longitude, Latitude width, Longitude width, Country, State, County, Admin Unit (3rd Geographic Unit), Lake characteristics, publication id
  2. Collection unit information:  CU ID, Type, Collection unit name, Collection unit handle, Location in site, Collection device, Date collected, Water depth of collection
  3.  Dataset information: Data Type (Diatom, Diatom surface sample, or Diatom top-bottom), Primary publication, Investigators [or first author of publication], Sample analyst


# Create output files for data analysis

The create data output files section -  standard formats for diatom counts, metadata, chronology, water chemistry.  It provides examples for retrieving data and creating output files in a few basic formats.  Formats include those that can be used as input to data analysis programs - R packages and others.  In general, they should include all related data; the amount of data can be reduced later.They will include several descriptive variables and be easily readable. [input to code chunks can include output from browse tasks]

## Basic files / matrices

### Diatom counts
- single sites and multiple sites; aggregate data set; stratigraphic vs surface sample vs top-bottom; percentages vs raw counts.

#### Create a count data file for a single site
JERRIN / SIMON - code does not run - "Error in get_dataset.default(schrader) : siteid must be numeric."
```{r get_singleSitebyName}
schrader <- get_sites(sitename = 'Schrader Pond') # % can be used to approximate sitenames
schrader.data <- get_datasets(schrader)
schrader.dl <- get_download(schrader.data)
schrader.cnt <- counts(schrader.dl)
sapply(schrader.cnt, dim) 
print(schrader.dl)
```

EXAMPLE TESTING OF FILTERING 
```{R UpperWallfaceEXAMPLE}
uwallface <-get_site('Upper Wallface%') 
uwall <- get_dataset(32252) # diatom datasetid for UWall is 32252
uwallface.dl <- get_download(uwall)
## Sapplyy function is used to return diatomss and with the function it is reading the metadata and selectind dataset,id to query from first 20 lakes 
#### JERRIN Review this example with me
subsetUWall <- sapply(uwall, 
                   function(x) {
                     x$dataset.meta$dataset.id
                   })

if('UWall' %in% list.files()) {
  UWa_dl <- readRDS('schra') # It returns the file that is used 
} else {
  UWallf_dl <- get_download(subsetUWall)
  saveRDS(UWallf_dl, 'schra') # It saves this as an object of the download with file
}

wideCounts <- compile_downloads(UWallf_dl) 
## neotoma function converts multiple downloads into single object 
minRow <- wideCounts %>% 
  group_by(dataset) %>% #dataset was returned from the table 
  summarise(min(depth)) #dplyr function to create a dataframe
  
wideCounts %>% filter(!is.na(Eunotia.diodon))
## dplyr function used to subset a data frame
diat_taxa <- taxa(UWallf_dl)
```
Upper Wallface Pond examples
```{R Upper Wallface EX}
library (neotoma)
### Find Neotoma Site Id for Upper Wallface Pond 
uwallface <- get_site (sitename = "Upper Wallface%")
### Find datasets and IDs associated with U Wallface Pond
uwallface.dl<- get_dataset(uwallface)  # Review datasets available note ID of the one of interest
### download data for diatom core dataset (Dataset 32252)
uwallface.dw <- get_download (32252)
### Get diatom counts for dataset 32252
uwallface.ct <- counts (uwallface.dw)
### Find the number of intervals and number of taxa in a count
sapply(uwallface.ct, dim)
### Look at the matrix of diatom counts
glimpse (uwallface.ct)
str(uwallface.dw) # str is a useful function to see the overall data structure for a dataset 
```

```{R Upper Wallface View counts}
### View sample metadata, list of taxa, and counts in Download dataframes 
### View sample metadata,
uwallface.dw[["32252"]][["sample.meta"]] 
### View taxa list
uwallface.dw[["32252"]][["taxon.list"]]
### View diatom counts
uwallface.dw[["32252"]][["counts"]]
### View Chronology
uwallface.dw[["32252"]][["chronologies"]]
```

#### Get count data for a diatom surface sample
Get data from from all datasets of "diatom" and diatom surface sample dataset types
Example of getting surface sample through filtering and usng multiple data set types to get metadata
Note: similar code for getting output of water chmistry data is below, around line 350
```{R datasetByTaxa with DBT}
## Simon Edited this:
diatomss<- get_dataset(datasettype = 'diatom surface sample')
diatom<- get_dataset(datasettype = 'diatom')
#SIMON - "diatom top-bottom" needs to be added as a choice for datasettype.
#Sapplyy function is used to return diatomss and with the function it is reading the metadata and selecting dataset,id to query from first 20 lakes 
subsetss <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id 
                   })
#In the subsets it would go through each dataset to match the search of the metadata location 
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') # It returns the file that is used 
} else {
  diat_dl <- get_download(subset)
  diat_dlss <- get_download(subsetss)
  diat_dl <- setdiff(diat_dl, diat_dlss)
  saveRDS(diat_dl, 'filename') # It saves this as an object of the download with file
}

wideCounts <- compile_downloads(diat_dl) 
#neotoma function converts multiple downloads into a single object 
minRow <- wideCounts %>% 
  group_by(dataset) %>% #dataset was returned from the table 
  summarise(min(depth)) #dplyr function to create a dataframe 
#Overall count data is retrieved from this portion 
wideCounts %>% filter(!is.na(Eunotia.diodon))
#dplyr function used to subset a data frame
diat_taxa <- taxa(diat_dl)
```

 

Example of using get_dataset to get diatom top-bottom samples (currently not usable since Top-Bottom not in package)
```{R datasetByTB,eval=FALSE}
library(neotoma)
diatomss<- get_dataset(datasettype = 'diatom top-bottom') # top-bottom not a dataset yet
diatom<- get_dataset(datasettype = 'diatom')
#Sapplyy function is used to return diatomss and with the function it is reading the metadata and select in dataset,id to query from first 20 lakes 
subsettb <- sapply(diatomss, 
                 function(x) {
                   x$dataset.meta$dataset.id # Location of the data
                   })[1:20]
#In the subsets it would go through each dataset to match the search of the metadata location
subset <- sapply(diatom, 
                 function(x) {
                   x$dataset.meta$dataset.id
                   })[1:20]

if('filename' %in% list.files()) {
  diat_dl <- readRDS('filename') 
} else {
  diat_dl <- get_download(subset)
  diat_dltb <- get_download(subsettb)
  diat_dl <- bind(diat_dl, diat_dltb)
  saveRDS(diat_dl, 'filename')
}
#It would return results of the top-bottom to bind them and present in a table format 
```


### List of diatom taxa 
- with name, authority, code, notes, etc.
```{R, diatom taxa out}
get_table(taxa)
get_taxa()
compile_taxa
```
Example of returning taxa 
```{R ListTaxaExample}
get_dataset(taxonids = )
get_dataset(datasettype = 'Diatom',taxonname = 'x')
```
## Site information and environ data

### Water chemistry
```{R WCHM Out}
get_dataset(sitename='x',datasettype = 'diatom')
```
Example
```{R ChemistryExample}

```
### Chronology


### Metadata - various options
```{R Metadata}
get_download()# Options within diatoms to organize it 
get_dataset()
```
Example
```{R DownloadStuffExample}
get_download()
get_dataset()
```

### Other types of data 
- LOI, geochemistry
```{R ETC}
get_dataset(datasettype="")
```
Example
```{R ETC EX}
get_dataset(siteid=,)
```


Issues:  Put metadata in the same files as the data matrices?  How to combine related files (e.g., diatom counts and chronology)? [When is it best to convert diatom counts to percentages?]

## Input files for data analysis programs
  Some programs have no standard input format
### Bacon, ### Vegan, ### Rioja, ### Tidypaleo
### Others 

#Make plots and maps 
(e.g., stratigraphic diagrams, maps of taxa distributions)

```{r plot}
library(leaflet)
test <- c(44764, 44765, 44766)
all_wi <- neotoma::get_dataset(test, datasettype = "diatom")
# We're going to use this multiple times I think, so let's make it a function:
leaflet_map <- function(dataset_in) {
  dataset_summary <- do.call(rbind, lapply(dataset_in, 
                        function(x){
                          # here we pull out the site information from the `dataset` objects:
                          data.frame(name = x$site.data$site.name,
                                     lat  = x$site.data$lat + runif(1, -0.005, 0.005),
                                     long = x$site.data$long + runif(1, -0.005, 0.005),
                                     type = x$dataset.meta$dataset.type)
                        }))
  # The leaflet package documentation uses piping.  For the sake of this tutorial, I won't.
  # First, define a color palette for the dataset type symbol plotting.
  pal <- colorFactor("Dark2", domain = levels(dataset_summary$type))
  # Now make the leaflet map, add base raster tiles and then add the markers for the records:
  map <- leaflet(data = dataset_summary)
  map <- leaflet::addTiles(map)
  map <- leaflet::addCircleMarkers(map, ~long, ~lat, 
                                   popup = ~paste0("Site: ", as.character(name), "<br>",
                                                   "Type: ", 
                                                   as.character(dataset_summary$type)),
                                   color = ~pal(type),
                                   stroke = FALSE, fillOpacity = 0.5)
  # You need to explicitly call the `map` object to make it appear!
  map
}
# Since that's all wrapped in a function, we can all it with any `dataset_list`:
leaflet_map(all_wi)
```



###Plot of the abundance of multiple diatom taxa 
for a single core - vs depth or time
###Plot of abundance of a single taxon 
for cores from multiple sites - vs time
### Plot of abundance of a taxon vs an environmental characteristic 
(e.g., water chemistry variable)
### Map of distribution of sites 
For example, that are part of an aggregate dataset; GGPlot, Leaflet
### Map of distribution of a diatom taxon
; symbol size related to % abundance

#Modify and analyze data 
- and other miscellaneous tasks
## Add to or modify data in Neotoma

### Add aggregate datasets to Neotoma

### Create new ecological groups and assign taxa to the groups
```{R set taxa}
set_taxa('x') # Not code but could be something

Example
```{R set taxa ex}

```

### Add to a table that explicitly matches water chemistry and diatom datasets
This is especially important for cases where sites were sampled for water chemistry as part of more than one study.

## Extract a list of publications for a set of datasets
```{R get pub out}
<- get_publications(datasetid= x)
### JERRIN - review following example with me
### So it would involve contact name/ID, publication ID, datasets having publication  
```

## Extract a list of DOI’s for a set of datasets
```{R DOIS}
get_publications(datasetid=)# Not code seems to need to be a mix of get_dataset and get_publications
```
Example
```{R DOIS EX}

```

## Add standard sets of diatom taxa names that could be used to convert multiple synonyms to another set of names
```{R standard set}
get_dataset(taxonname = ,search())
```

# Create Output files
The following items will be moved to corresponding topics in the outline above
## Diatom counts
SIMON ASSISTED EXAMPLE [Example provided by Simon Goring - date]
Creates file with diatom counts for surface samples 
```{R datasetByTaxa from Simon}
library(dplyr)
library(purrr)
# Get diatom datasets (Diatom and Diatom Surface Sample data types) for all sites in the northeast US, defined as a set of states.
gpids <- c(8412, 7990, 7934, 7326, 7923, 8981, 6442, 7368)

ne_diatom <- map(gpids, function(x)
  neotoma:::get_dataset(gpid = x,datasettype="diatom")) %>%
  neotoma::bind()   
  
ne_diatomSS <- map(gpids, function(x)
  neotoma:::get_dataset(gpid = x,datasettype="diatom surface sample"))%>% 
  neotoma::bind() 
ne_dataset<-bind(ne_diatom,ne_diatomSS)


if('DiatomFil' %in% list.files()) {
  Diatom_dl <- readRDS('DiatomFil') 
} else {

  allDatasets <- list()
  
  for(i in length(allDatasets):length(ne_dataset)) {
    allDatasets[[i]] <- get_download(ne_dataset[[i]])
  }
  
  ne_download <- neotoma::bind(allDatasets)
  
  saveRDS(ne_download, 'DiatomFil')
}

# Create diatom count files
wideCounts <- compile_downloads(Diatom_dl) 
minRow <- wideCounts %>% 
  group_by(dataset) %>% 
  summarise(min(depth)) 
```

Jerrin Example of using just dataset ID
### Example similar to above but starting with a set of dataset ID's
```{R ExampleDataset}
library(purrr)
V1 <-c(44786,44787,44788)
#In this example we take these 3 sites with combine function 
V1_diatom <- map(V1, function(x)
  neotoma:::get_dataset(x,datasettype="diatom")) %>%
  neotoma::bind()   
#In the get_dataset line, whatever is in the parenthesis is a parameter such as x or gpid in which it will take from V1 since it was stated in the line above it

if('V1' %in% list.files()) {
  V1_dl <- readRDS('V1') 
} else {

  V1Datasets <- list()
  #
  for(i in 1:length(V1_diatom)) {
    V1Datasets[[i]] <- get_download(V1_diatom[[i]])
  }
  #For loop will being going through each step to first create the file and go through each site with the download
  V1_download <- neotoma::bind(V1Datasets)
  
  saveRDS(V1_download, 'V1')
}
V1Counts <- compile_downloads(V1_download) 
V1Row <- V1Counts %>% 
  group_by(dataset) %>% 
  summarise(min(depth))
write_xlsx(V1Counts,  ".xlsx")

#This last step is the way to create a table which can be written as csv to export out 

```

Example of getting information for a single site ID using get_dataset with subsets to return counts.  Created by Simon Goring
add comments
```{R ExampleSingleSite }
Mirror<- get_dataset(39813) # Dataset ID for Mirror Lake, Newer dataset/ site ids does not seem to work 
subsetda <- sapply(Mirror, 
                 function(x) {
                   x$dataset.meta$dataset.id 
                   })
# The subset is not a function but a way to filter the dataset to get the portions of interest and sapply is from R package  
if('Mirror' %in% list.files()) {
  diat_da <- readRDS('Mirror') 
} else {
  diat_dla <- get_download(subsetda)
  saveRDS(diat_dla, 'Mirror')
}
#In the if and else loops they work together that a file will be created and download the data from the subset
diatCount <- compile_downloads(diat_da) 
minimumRow <- diatCount %>% 
  group_by(dataset) %>% 
   summarise(min(depth))
#In compiling downloads it displays the information in a table format and could be organized with group_by and summarise function
```


