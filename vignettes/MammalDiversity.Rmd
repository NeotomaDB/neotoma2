---
title: "Mammal Diversity in the Holocene"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Mammal Diversity in the Holocene}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup, eval=TRUE}
library(neotoma2)
library(raster)
```

This is a model workflow to help understand and map faunal assemblage diversity across time and space.  There are more neotoma2 vignettes, for diatoms and for pollen generally.  This vignette specifically addresses the use of the package to manage and understand how the package can be used to work with vertabrate faunal data.

## Obtain Data
### Obtain all Neotoma Mammal Data

Download occurrence and age data from Neotoma: All vertebrate occurrences for XX region (North America, global) for a particular time window.

By default the API calls have a `limit` of 25 records at a time. Given this the call:

```{r getRecords, eval=TRUE, message=FALSE}
faunal <- get_datasets(datasettype = 'vertebrate fauna')
```

would return only the first 25 records in Neotoma.  We can create an interactive spatial plot using the `plotLeaflet()` command to display the records:

```{r plotSmallSites, eval=TRUE}
plotLeaflet(faunal)
```

The default for all calls to the Neotoma API is to set a `limit` of 25, but often we want all records.  There are two ways of obtaining all the records.  One is to increase the `limit` parameter, for example, calling:

```{r}
get_datasets(datasettype = 'vertebrate fauna', limit = 999999)
```

**Please don't do this**.  The issue is that it is computationally expensive for the database itself; it takes much longer for the single query, so an error at any point would result in you retrieving no records at all; and, you don't know how many records you might be getting, so if it's a very large table you might run out of local memory.

One way of dealing with the issue of `offsets` and `limits` is the use of a `while` loop, that runs by increasing the `offset`, until the result returns less that 25 records (the default `limit`).  If we look at the code below we can imagine that if there were 31 total records the first return would have `offset` 0 (`counter` is 1, so `(counter - 1) * 25` is 0), and would return all 25 records.  The second loop would return 6 records, and result in a `break` since `length(mammalSet[[counter]]) < 25`.  Once we break, we put all the results together using the `c()` command.

```{r downloadMammals}
# This gives us 25 records (without setting 'limit')
mammals <- get_datasets(datasettype = 'vertebrate fauna')

# The 'while loop' approach:
counter <- 1
mammalSet <- c()

while (TRUE) {
  mammals <- get_datasets(datasettype = 'vertebrate fauna',
                          offset = (counter - 1) * 25)
  if (length(mammals@sites) < 25 | counter > 4) {
    break
  } else {
    mammalSet <- c(mammals, mammalSet)
    counter = counter + 1
  }
}

```

```{r dummyBox, eval=TRUE, results='hide', echo=FALSE}
mammalSet <- -9999
```

Now we have all our records, totaling `r length(mammalSet)` distinct mammal sites.  This accounts for `r length(mammalSet)` distinct datasets.  Note that these objects are all class `sites`, but that these `sites` contain `collectionunits` and `datasets`.  The `get_datasets()` command does not explicitly download the raw data.

### Obtain Secondary (Environmental) Data

Download climate data from appropriate source.

```{r, eval=TRUE}
worldTmin <- raster::getData('worldclim', var = 'tmin', res = 10)

raster::plot(worldTmin, 1)
```

This is just an example of downloading one element of [WorldClim](https://www.worldclim.org/) data as a raster in R. This particular raster has `r raster::nlayers(worldTmin)` layers and is a global dataset.  The `raster` package for R has a number of links to external datasets such as WorldClim.  Alternately you can load in your own data.

## Cleaning Data

The basis of any workflow is downloading appropriate data. Lets begin again with downloading all records for mammals within the database that have a Holocene age.  Here we use the `get_datasets()` command, and set `ageold` to be `12000`.  Dates passed to the API are assumed to be in calibrated radiocarbon years before present.

```{r}
mamData <- get_datasets(datasettype = "vertebrate fauna", 
                        ageold = 12000, 
                        limit = 99999)
plotLeaflet(mamData)
dsid <- getids(mamData)
mamDl <- get_downloads(1001)
```

### Clean ages


  * ensure taxa are really within the target age range
  * Assess what age controls are used for each species/occurrence?
  * Exclude certain dating methods (e.g. $^{14}C$ on apatite, or biostratigraphic data, or… high grade based on the narrowness of the date control or error bars)

### Clean taxonomy

  *  Determine possible taxonomic level (species, genus)
account for uncertain taxa (cf., aff., type, ?) → taxa harmonization table

### Clean Spatial Records

  * For each species across all sites:
  * Check for geographic/environmental outliers

## Assemble Cleaned Data

  * Create convex hulls (at     multiple time bins?)
Evaluate which convex hulls intersect with /come within a buffer of point of interest

### Join Hulls with Environmental Data
  
  * Apply the convex hull to look at the environmental space occupied by the taxon

## Build SDMs
  
  * Create SDMs for taxon with intersection convex hulls
  * Assess which SDMs intersect with point of interest
